{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies\n",
    "import numpy as np # calcul matriciel\n",
    "import pandas as pd # structure des donnees\n",
    "import matplotlib.pyplot as plt # graphique\n",
    "\n",
    "# Chemin vers les jeux de donnees en format csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# On importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)\n",
    "\n",
    "\n",
    "# --- Variables Explicatives ---\n",
    "\n",
    "#    Name : Nom du jeu\n",
    "#    Platform : Console sur laquelle le jeu fonctionne\n",
    "#    Year_of_Release : Année de sortie du jeu\n",
    "#    Genre\n",
    "#    Publisher\n",
    "#    JP_Sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "#    Other_Sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "#    Critic_Score : Score donné par Metacritic\n",
    "#    Critic_Count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "#    User_Score : Score donné par les usagers de Metacritic\n",
    "#    User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "#    Developer : Compagnie créatrice du jeu\n",
    "#    Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "\n",
    "# --- Variables d'Interet ---\n",
    "\n",
    "#    NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "#    Global_Sales : Nombre de ventes total du jeu en millions d’unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "On definit ici la fonction qui calcule les coefficients de notre regression lineaire\n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : matrice contenant nos variables explicatives (dimension : n x p)\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative\n",
    "        \n",
    "        \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = coefficiants de regression\n",
    "\n",
    "    Pour estimer la valeur de y_new avec de nouvelles observations (i.e. x_new) on a,\n",
    "        y_new = np.dot(x_new,B)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def linear_regression(y,x):\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance\n",
    "    C = np.linalg.inv(np.dot(x.T,x))\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(np.dot(C,x.T),y)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous avons une fonction qui la tranforme en table binaire \n",
    "avec un one bit encoder. \n",
    "\n",
    "    Disons que la variable explicative peut prendre 4 valeurs {Bleu, Vert, Jaune, Rouge},\n",
    "        \n",
    "          ID        X1\n",
    "        ----------------\n",
    "          1        Bleu\n",
    "          2        Bleu\n",
    "          3        Vert\n",
    "          4        Jaune\n",
    "          5        Vert\n",
    "          6        Rouge          \n",
    "         ...\n",
    "    \n",
    "    Suite a un encodage en 1 bit notre variable explicative X1 devient,\n",
    "    \n",
    "          ID        Bleu        Vert        Jaune        Rouge\n",
    "        -------------------------------------------------------\n",
    "          1          1           0            0            0\n",
    "          2          1           0            0            0\n",
    "          3          0           1            0            0\n",
    "          4          0           0            1            0\n",
    "          5          0           1            0            0\n",
    "          6          0           0            0            1\n",
    "                                ...\n",
    "                                \n",
    "\n",
    "Nous nous basons sur la fonction get_dummies() de la librairie Panda pour faire ceci.\n",
    "\n",
    "\n",
    "Arguments,\n",
    "\n",
    "    trainSet : le jeu de donnees de training\n",
    "    testSet : le jeu de donnees de test\n",
    "    varName : la variable qualitative que nous souhaitons transformer en tableau binaire\n",
    "    \n",
    "    \n",
    "Retourne, \n",
    "    trainSet_new : le jeu de donnees de training ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "    testSet_new : le jeu de donnees de test ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def qualiToBinary(trainSet, testSet, varName):\n",
    "    \n",
    "    # Genere la table binaire de la variable qualitative\n",
    "    trainVar_binary = pd.get_dummies(trainSet[varName],prefix=varName)\n",
    "    testVar_binary = pd.get_dummies(testSet[varName],prefix=varName)\n",
    "    \n",
    "    # On convertit nos tableaux binaires en Dataframe\n",
    "    trainVar_binary = pd.DataFrame(trainVar_binary)\n",
    "    testVar_binary = pd.DataFrame(testVar_binary)\n",
    "    \n",
    "    # On enleve la variable qualitative de nos jeux de donnees\n",
    "    trainSet_new = trainSet.drop([varName], axis=1)\n",
    "    testSet_new = testSet.drop([varName], axis=1)   \n",
    "\n",
    "    # On ajoute les nouvelles colonnes a nos jeux de donnees\n",
    "    trainSet_new = pd.concat([trainSet_new,trainVar_binary],axis=1)\n",
    "    testSet_new = pd.concat([testSet_new,testVar_binary],axis=1)\n",
    "    \n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees test\n",
    "    missing_categories = set(trainSet_new) - set(testSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        testSet_new[c] = 0\n",
    "\n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees training\n",
    "    missing_categories = set(testSet_new) - set(trainSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        trainSet_new[c] = 0\n",
    "\n",
    "\n",
    "    # On aligne nos jeux de donnees pour que les memes colonnes soient aux memes endroits\n",
    "    trainSet_new, testSet_new = trainSet_new.align(testSet_new, axis=1)\n",
    "    \n",
    "    # On retourne les jeux de donnees\n",
    "    return trainSet_new, testSet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "L'algorithme R2_prev implemente une validation croise sur l'ensemble du jeu de donnees fournis\n",
    "\n",
    "Arguments:\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    X : Nos variables explicatives\n",
    "    \n",
    "    \n",
    "Retourne:\n",
    "    R2_prev : Une mesure bornee entre [-inf, 1] qui represente le pouvoir predictif de nos estimations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def R2_prev(Y,W,X):\n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(np.dot(X.T,X))\n",
    "    \n",
    "    # Hat Matrix (X*B = H*Y)\n",
    "    H = np.dot(np.dot(X,C),X.T)\n",
    "    \n",
    "    # We are only interested in the (i,i) values\n",
    "    H = np.diagonal(H)\n",
    "    \n",
    "    # Mean of Y\n",
    "    y_S = np.sum(Y)/float(len(Y))\n",
    "    \n",
    "    num = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        num += ((Y[i] - W[i])/float(1 - H[i]))**2\n",
    "\n",
    "    denom = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        denom += (Y[i] - y_S)**2\n",
    "    \n",
    "    R2_prev = (1 - num/denom)\n",
    "    \n",
    "    return R2_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction qui affiche la quantite de NaN par colonne\n",
    "\n",
    "Argument:\n",
    "    dataset : Le jeu de donnees sur lequel nous appliquons la fonction\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def printNaN(dataset):\n",
    "    for col in dataset:\n",
    "        if(dataset[col].isna().sum() > 0):\n",
    "            print('%d \\t %s' % (dataset[col].isna().sum(),col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fonction qui affiche la valeur moyenne de la variable d'interet en fonction des \n",
    "valeurs d'une variable explicative qualitative.\n",
    "\n",
    "Arguments:\n",
    "    dataset : Le jeu de donnees sur lequel nous appliquons la fonction\n",
    "    Y : la variable d'interet\n",
    "    colName : Le nom de la variable qualitative que nous souhaitons etudier\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clusterVar(dataset,Y,colsName):\n",
    "    \n",
    "    # On selectionne seulement les colonnes qui debute par 'colsName'\n",
    "    reducedSet = dataset.loc[:, dataset.columns.str.startswith(colsName)]\n",
    "    \n",
    "    # On calcule le nombre de colonne\n",
    "    nbrOfCols = len(reducedSet.T)\n",
    "    \n",
    "    # On cree une liste d'index de 0 au nombre de colonne\n",
    "    rangeIndex = np.array(range(nbrOfCols))\n",
    "    \n",
    "    sumWithX = np.zeros(nbrOfCols)\n",
    "    valueCount = np.zeros(nbrOfCols)\n",
    "    names = np.array(['' for _ in range(nbrOfCols)], dtype=object)\n",
    "    index = 0\n",
    "    for col in reducedSet:\n",
    "        withX = reducedSet[col]*Y\n",
    "        sumWithX[index] = np.sum(withX)/(withX.astype(bool).sum(axis=0))\n",
    "        valueCount[index] = reducedSet[col].astype(bool).sum(axis=0)\n",
    "        names[index] += col\n",
    "        index += 1\n",
    "    \n",
    "    # On cree un tableau indexe de nos categories, leur quantite et leur valeur moyenne de la variable d'interet\n",
    "    aveY_table = np.array(([rangeIndex,sumWithX,valueCount,names])).T\n",
    "    \n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    aveY_table_ordered = aveY_table[(-aveY_table[:,1]).argsort()]\n",
    "    \n",
    "    print('Index \\t X \\t Nbr \\t Name')    \n",
    "    print('------------------------------------------')\n",
    "    for i in range(nbrOfCols):\n",
    "        print('%d. \\t %.3f \\t %d \\t %s ' % (aveY_table_ordered[i][0],aveY_table_ordered[i][1],aveY_table_ordered[i][2],aveY_table_ordered[i][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 30\n",
      "Nbr. of categories (test) : 27\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Platform.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Platform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 12\n",
      "Nbr. of categories (test) : 12\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Genre.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 552\n",
      "Nbr. of categories (test) : 280\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Publisher.nunique()))\n",
    "\n",
    "#df_train, df_test = qualiToBinary(df_train, df_test, 'Publisher')\n",
    "df_test = df_test.drop(['Publisher'],axis=1)\n",
    "df_train = df_train.drop(['Publisher'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 1593\n",
      "Nbr. of categories (test) : 677\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Developer.nunique()))\n",
    "\n",
    "\n",
    "# Bon ici on a un probleme, si on ajoute les colonnes binaires generees par cette variable on ajoute 100mb\n",
    "# a notre csv. Ceci rend peu pratique le prototypage, pour l'instant on le laisse tomber. On essayera de ce\n",
    "# donner une raison rationnelle de le domper plus tard dans l'analyse. Hypothese, beaucoup de colinearite avec \n",
    "# le Publisher.\n",
    "\n",
    "#df_train, df_test = qualiToBinary(df_train, df_test,'Developer')\n",
    "df_test = df_test.drop(['Developer'],axis=1)\n",
    "df_train = df_train.drop(['Developer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 8\n",
      "Nbr. of categories (test) : 5\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Rating.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = df_train.fillna(df_train.median()).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index \t X \t Nbr \t Name\n",
      "------------------------------------------\n",
      "4. \t 0.519 \t 748 \t Genre_Platform \n",
      "8. \t 0.442 \t 1116 \t Genre_Shooter \n",
      "10. \t 0.304 \t 1993 \t Genre_Sports \n",
      "6. \t 0.295 \t 1064 \t Genre_Racing \n",
      "0. \t 0.260 \t 2842 \t Genre_Action \n",
      "2. \t 0.254 \t 712 \t Genre_Fighting \n",
      "3. \t 0.247 \t 1487 \t Genre_Misc \n",
      "5. \t 0.220 \t 478 \t Genre_Puzzle \n",
      "7. \t 0.209 \t 1264 \t Genre_Role-Playing \n",
      "9. \t 0.192 \t 731 \t Genre_Simulation \n",
      "11. \t 0.100 \t 579 \t Genre_Strategy \n",
      "1. \t 0.081 \t 1078 \t Genre_Adventure \n"
     ]
    }
   ],
   "source": [
    "clusterVar(df_train_clean,df_train_clean.NA_Sales.values,'Genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_Global(testSet):\n",
    "    \n",
    "    X1 = testSet.JP_Sales.values\n",
    "    X2 = (testSet.Critic_Count.values**2)*(testSet.Critic_Score.values)\n",
    "    X3 = (testSet.Critic_Score.values)\n",
    "    X4 = testSet.Year_of_Release.values\n",
    "    X5 = testSet.Other_Sales.values\n",
    "    X6 = testSet.User_Score.values*testSet.User_Count.values**2\n",
    "    X7 = testSet.User_Count.values\n",
    "    \n",
    "    X8_1 = testSet.Platform_NES.values+testSet.Platform_GB.values+testSet.Platform_GEN.values+testSet.Platform_SNES.values\n",
    "    X8_2 = testSet.Platform_X360.values+testSet.Platform_PS4.values+testSet.Platform_2600.values+testSet.Platform_Wii.values+testSet.Platform_PS3.values+testSet.Platform_N64.values\n",
    "    X8_3 = testSet.Platform_XOne.values+testSet.Platform_GBA.values+testSet.Platform_GC.values+testSet.Platform_DS.values+testSet.Platform_XB.values\n",
    "    \n",
    "    X9_1 = testSet.Genre_Platform.values\n",
    "    X9_2 = testSet.Genre_Shooter.values+testSet.Genre_Racing.values+testSet.Genre_Sports.values\n",
    "\n",
    "    X9_3 = testSet['Genre_Role-Playing'].values\n",
    "    \n",
    "    X = np.array([np.ones(len(testSet.JP_Sales)),\n",
    "                  X1,X2,X3,X4,X5,X6,X7,\n",
    "                  X8_1,X8_2,X8_3,\n",
    "                  X9_1,X9_2,X9_3]).T\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev (Global) : 0.6827\n"
     ]
    }
   ],
   "source": [
    "Y1 = df_train_clean.Global_Sales.values\n",
    "X1 = createX_Global(df_train_clean)\n",
    "B1 = linear_regression(Y1,X1)\n",
    "\n",
    "# Clip to min 0\n",
    "global_data = np.dot(X1,B1)\n",
    "global_data = global_data.clip(min=0)\n",
    "\n",
    "print(\"R2_prev (Global) : %.4f\" % (R2_prev(Y1,global_data,X1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_NA(testSet):\n",
    "    \n",
    "    X1 = testSet.JP_Sales.values\n",
    "    X2 = (testSet.Critic_Count.values)*(testSet.Critic_Score.values)\n",
    "    X3 = testSet.Year_of_Release.values\n",
    "    X4 = testSet.Other_Sales.values\n",
    "    X5 = testSet.User_Score.values*testSet.User_Count.values**2\n",
    "    X6 = testSet.User_Count.values\n",
    "    \n",
    "    X8_1 = testSet.Platform_NES.values+testSet.Platform_GB.values+testSet.Platform_GEN.values\n",
    "    X8_2 = testSet.Platform_2600.values+testSet.Platform_X360.values+testSet.Platform_N64.values+testSet.Platform_Wii.values+testSet.Platform_XOne.values\n",
    "    X8_3 = testSet.Platform_GC.values\n",
    "    \n",
    "    X9_1 = testSet.Genre_Platform.values+testSet.Genre_Shooter.values\n",
    "    X9_2 = testSet['Genre_Role-Playing'].values\n",
    "    \n",
    "   \n",
    "    \n",
    "    X = np.array([np.ones(len(testSet.JP_Sales)),\n",
    "                  X1,X2,X3,X4,X5,X6,\n",
    "                  X8_1,X8_2,X8_3,\n",
    "                  X9_1,X9_2]).T\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA R2_prev : 0.452\n"
     ]
    }
   ],
   "source": [
    "Y2 = df_train_clean.NA_Sales.values\n",
    "X2 = createX_NA(df_train_clean)\n",
    "B2 = linear_regression(Y2,X2)\n",
    "  \n",
    "# Clip to min 0\n",
    "na_data = np.dot(X2,B2)\n",
    "na_data = na_data.clip(min=0)\n",
    "\n",
    "print(\"NA R2_prev : %.3f\" % (R2_prev(Y2,na_data,X2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_clean = df_test.fillna(df_test.median()).copy()\n",
    "\n",
    "X1_test = createX_Global(df_test_clean)\n",
    "X2_test = createX_NA(df_test_clean)\n",
    "\n",
    "test_GlobalData = np.dot(X1_test,B1)\n",
    "test_NAData = np.dot(X2_test,B2)\n",
    "\n",
    "# Clip to min 0\n",
    "test_GlobalData = test_GlobalData.clip(min=0)  \n",
    "\n",
    "# Clip to min 0\n",
    "test_NAData = test_NAData.clip(min=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "df_test_estimated['NA_Sales'] = test_NAData\n",
    "df_test_estimated['Global_Sales'] = test_GlobalData\n",
    "df_test_estimated.to_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
