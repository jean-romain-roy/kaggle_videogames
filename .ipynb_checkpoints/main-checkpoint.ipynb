{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies\n",
    "import numpy as np # calcul matriciel\n",
    "import pandas as pd # structure des donnees\n",
    "\n",
    "# Chemin vers les jeux de donnees en format csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# On importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)\n",
    "\n",
    "# On enleve la colonne Name qui ne sert pas a l'analyse\n",
    "df_train = df_train.drop(['Name'],axis=1)\n",
    "\n",
    "\n",
    "# --- Variables Explicatives ---\n",
    "\n",
    "#    Name : Nom du jeu\n",
    "#    Platform : Console sur laquelle le jeu fonctionne\n",
    "#    Year_of_Release : Année de sortie du jeu\n",
    "#    Genre\n",
    "#    Publisher\n",
    "#    JP_Sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "#    Other_Sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "#    Critic_Score : Score donné par Metacritic\n",
    "#    Critic_Count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "#    User_Score : Score donné par les usagers de Metacritic\n",
    "#    User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "#    Developer : Compagnie créatrice du jeu\n",
    "#    Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "\n",
    "# --- Variables d'Interet ---\n",
    "\n",
    "#    NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "#    Global_Sales : Nombre de ventes total du jeu en millions d’unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Regression de Ridge (L2) par methode des moindres carres permettant la penalisation du surapprentissage.\n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : matrice contenant nos variables explicatives (dimension : n x (p+1))\n",
    "    l : facteur qui permet de diminuer l'amplitude des coefficients de regression\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative       \n",
    "        \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = Matrices de nos coefficiants de regression (dimension (p+1) x 1)\n",
    "\n",
    "    Pour estimer la valeur de y_new avec de nouvelles observations (i.e. x_new) on a,\n",
    "        y_new = np.dot(x_new,B)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def ridge_regression(y,x,l):\n",
    "    \n",
    "    # Nombre de variable explicative + colonne de 1\n",
    "    nbr = len(x.T)\n",
    "    \n",
    "    # Matrice identite de taille p+1\n",
    "    identi = l*np.identity(nbr) \n",
    "    identi[0][0] = 0 # on met un zero vis a vis le coeff b0 qui est l'ordonnee a l'origine\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance avec un biais de penalite\n",
    "    C = np.linalg.inv(np.dot(x.T,x) + np.dot(l,identi))\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(np.dot(C,x.T),y)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Fonction permettant de transformer une matrice pour que ses colonnes aient une moyenne = 0 et une variance = 1\n",
    "\n",
    "Argument:\n",
    "    dataset : le jeu de donnees a transformer\n",
    "    \n",
    "Retourne :\n",
    "    dataset_std : le jeu de donnees transforme\n",
    "\n",
    "\"\"\"\n",
    "def scaler(dataset):\n",
    "    \n",
    "    # On calcule la moyenne pour chaque colonne\n",
    "    u = np.array([np.mean(dataset, axis=0)])\n",
    "    \n",
    "    # On soustrait les colonnes du jeu de donnees par ses moyennes\n",
    "    dataset_std = dataset - u\n",
    "    \n",
    "    # On calcule la variance pour chaque colonne\n",
    "    sigma = np.array([np.std(dataset_std, axis=0)])\n",
    "    \n",
    "    # On divise les colonnes du jeu de donnees par ses variances\n",
    "    dataset_std = dataset_std/sigma\n",
    "    \n",
    "    # Si contient des NaN cause par une division par 0 (si la variance etait de 0)\n",
    "    if(np.isnan(dataset_std).any()):\n",
    "        print(\"Error will contain NaN\") # On affiche le message d'erreur\n",
    "        return np.all(np.isnan(dataset_std),axis=0) # On retourne les index ou il y a presence de NaN\n",
    "    \n",
    "    return dataset_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous avons une fonction qui la tranforme en table binaire \n",
    "avec un one bit encoder. \n",
    "\n",
    "    Disons que la variable explicative peut prendre 4 valeurs {Bleu, Vert, Jaune, Rouge},\n",
    "        \n",
    "          ID        X1\n",
    "        ----------------\n",
    "          1        Bleu\n",
    "          2        Bleu\n",
    "          3        Vert\n",
    "          4        Jaune\n",
    "          5        Vert\n",
    "          6        Rouge          \n",
    "         ...\n",
    "    \n",
    "    Suite a un encodage en 1 bit notre variable explicative X1 devient,\n",
    "    \n",
    "          ID        Bleu        Vert        Jaune        Rouge\n",
    "        -------------------------------------------------------\n",
    "          1          1           0            0            0\n",
    "          2          1           0            0            0\n",
    "          3          0           1            0            0\n",
    "          4          0           0            1            0\n",
    "          5          0           1            0            0\n",
    "          6          0           0            0            1\n",
    "                                ...\n",
    "                                \n",
    "\n",
    "Nous nous basons sur la fonction get_dummies() de la librairie Panda pour faire ceci.\n",
    "\n",
    "\n",
    "Arguments,\n",
    "\n",
    "    trainSet : le jeu de donnees de training\n",
    "    testSet : le jeu de donnees de test\n",
    "    varName : la variable qualitative que nous souhaitons transformer en tableau binaire\n",
    "    \n",
    "    \n",
    "Retourne, \n",
    "    trainSet_new : le jeu de donnees de training ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "    testSet_new : le jeu de donnees de test ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def qualiToBinary(trainSet, testSet, varName):\n",
    "    \n",
    "    # Genere la table binaire de la variable qualitative\n",
    "    trainVar_binary = pd.get_dummies(trainSet[varName],prefix=varName)\n",
    "    testVar_binary = pd.get_dummies(testSet[varName],prefix=varName)\n",
    "    \n",
    "    # On convertit nos tableaux binaires en Dataframe\n",
    "    trainVar_binary = pd.DataFrame(trainVar_binary)\n",
    "    testVar_binary = pd.DataFrame(testVar_binary)\n",
    "    \n",
    "    # On enleve la variable qualitative de nos jeux de donnees\n",
    "    trainSet_new = trainSet.drop([varName], axis=1)\n",
    "    testSet_new = testSet.drop([varName], axis=1)   \n",
    "\n",
    "    # On ajoute les nouvelles colonnes a nos jeux de donnees\n",
    "    trainSet_new = pd.concat([trainSet_new,trainVar_binary],axis=1)\n",
    "    testSet_new = pd.concat([testSet_new,testVar_binary],axis=1)\n",
    "    \n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees test\n",
    "    missing_categories = set(trainSet_new) - set(testSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        testSet_new[c] = 0\n",
    "\n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees training\n",
    "    missing_categories = set(testSet_new) - set(trainSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        trainSet_new[c] = 0\n",
    "\n",
    "\n",
    "    # On aligne nos jeux de donnees pour que les memes colonnes soient aux memes endroits\n",
    "    trainSet_new, testSet_new = trainSet_new.align(testSet_new, axis=1)\n",
    "    \n",
    "    # On retourne les jeux de donnees\n",
    "    return trainSet_new, testSet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "L'algorithme R2_prev implemente une validation croise sur l'ensemble du jeu de donnees fournis\n",
    "\n",
    "Arguments:\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    X : Nos variables explicatives\n",
    "    \n",
    "\n",
    "\n",
    "Retourne:\n",
    "\n",
    "    R2_prev : Une mesure bornee entre [-inf, 1] qui represente le pouvoir predictif de nos estimations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def R2_prev(Y,W,X):\n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(np.dot(X.T,X))\n",
    "    \n",
    "    # Hat Matrix (X*B = H*Y)\n",
    "    H = np.dot(np.dot(X,C),X.T)\n",
    "    \n",
    "    # We are only interested in the (i,i) values\n",
    "    H = np.diagonal(H)\n",
    "    \n",
    "    # Mean of Y\n",
    "    y_S = np.sum(Y)/float(len(Y))\n",
    "    \n",
    "    num = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        num += ((Y[i] - W[i])/float(1 - H[i]))**2\n",
    "\n",
    "    denom = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        denom += (Y[i] - y_S)**2\n",
    "    \n",
    "    R2_prev = (1 - num/denom)\n",
    "    \n",
    "    return R2_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Selon le document MTH3302_CriteresProjet.pdf nous sommes evalues par notre root mean squared error (RMSE).\n",
    "On trouve ici son implementation.\n",
    "\n",
    "Arguments :\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    \n",
    "    \n",
    "Retourne:\n",
    "    rmse : L'erreur moyenne de nos predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RMSE(Y,W):\n",
    "\n",
    "    n = len(Y)\n",
    "\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += (Y[i] - W[i])**2\n",
    "        \n",
    "    rmse = total/float(n)\n",
    "        \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 30\n",
      "Nbr. of categories (test) : 27\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Platform.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Platform') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 12\n",
      "Nbr. of categories (test) : 12\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Genre.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Genre') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 552\n",
      "Nbr. of categories (test) : 280\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Publisher.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Publisher') # On binairise\n",
    "#df_test = df_test.drop(['Publisher'],axis=1)\n",
    "#df_train = df_train.drop(['Publisher'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 1593\n",
      "Nbr. of categories (test) : 677\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Developer.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Developer') # On binairise\n",
    "#df_test = df_test.drop(['Developer'],axis=1)\n",
    "#df_train = df_train.drop(['Developer'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories (train) : 8\n",
      "Nbr. of categories (test) : 5\n"
     ]
    }
   ],
   "source": [
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Rating.nunique()))\n",
    "\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Rating') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute une colonne qui comptabilise le nombre de NaN pour chaque jeu video\n",
    "nbrOfNaN_train = ~(df_train.T.iloc[:].isna().sum().astype(bool))\n",
    "df_train['Complete_Data'] = nbrOfNaN_train.astype(np.uint8)\n",
    "\n",
    "nbrOfNaN_test = ~(df_test.T.iloc[:].isna().sum().astype(bool))\n",
    "df_test['Complete_Data'] = nbrOfNaN_test.astype(np.uint8)\n",
    "\n",
    "# Ici on remplace les NaN par la mediane de leur colonne\n",
    "df_train_clean = df_train.fillna(df_train.median()).copy()\n",
    "df_test_clean = df_test.fillna(df_test.median()).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on a une fonction pour nous aider a visualiser les coefficiants de regression.\n",
    "\n",
    "Puisque notre matrice de variables explicatives est normalisee, un haut coefficiant b_i indique \n",
    "une importance de la variable X_i\n",
    "\n",
    "Par contre nous ne testons pas ici des relations du type : log(X_i), X_i^2, X_(i+1)*X_i, etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cofficientTrier(dataset,Y,l,coeffThreshold):\n",
    "    \n",
    "    # On cree la matrice de nos variables explicatives\n",
    "    X = dataset.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "    \n",
    "    # On enleve les colonnes qui comportent que des 0\n",
    "    X = X.loc[:, (X != 0).any(axis=0)]\n",
    "    \n",
    "    # Transformation, moy = 0, var = 1\n",
    "    X_std = scaler(X.values)\n",
    "    \n",
    "    # On effectue la regression\n",
    "    B = ridge_regression(Y,X_std,l)\n",
    "    \n",
    "    # On calcule la somme des B\n",
    "    sumB = np.sum(np.abs(B))    \n",
    "    \n",
    "    # On calcule le nombre de colonne\n",
    "    nbrOfCols = len(X.T)\n",
    "    \n",
    "    \n",
    "    indexes = np.zeros(nbrOfCols)\n",
    "    coeffs = np.zeros(nbrOfCols)\n",
    "    coeffsFrac = np.zeros(nbrOfCols)\n",
    "    sumBFrac = 0\n",
    "    names = np.array(['' for _ in range(nbrOfCols)], dtype=object)\n",
    "    index = 0\n",
    "    index2 = 0\n",
    "    for col in X:\n",
    "        if((B[index]/sumB) >= coeffThreshold):\n",
    "            names[index2] += col\n",
    "            indexes[index2] = index\n",
    "            coeffs[index2] = B[index]\n",
    "            coeffsFrac[index2] = np.abs(B[index])/sumB\n",
    "            sumBFrac += coeffsFrac[index2]\n",
    "            index2 += 1\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    # On cree un tableau indexe de nos categories, leur quantite et leur valeur moyenne de la variable d'interet\n",
    "    table = np.array(([indexes,coeffsFrac,names])).T\n",
    "    \n",
    "    # On enleve les ranges de 0\n",
    "    table = table[~np.all(table == 0, axis=1)]\n",
    "    \n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    table_ordered = table[(-table[:,1]).argsort()] \n",
    "    \n",
    "    print(\"Fraction of B displayed = %.3f %%\" % sumBFrac)\n",
    "    print('Index \\t B_i %% \\t Name \\t (l = %.2f  -  minB = %.3f %%)' % (l,coeffThreshold))    \n",
    "    print('------------------------------------------')\n",
    "    for i in range(index2):\n",
    "        sumBFrac += table_ordered[i][1]\n",
    "        print('%d. \\t %.3f \\t %s ' % (table_ordered[i][0],table_ordered[i][1],table_ordered[i][2]))\n",
    "    \n",
    "    \"\"\" SI ON VEUT COPIER COLLER LE NOM DES VAR ON ENLEVE COMMENTAIRE\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    for i in range(index2):\n",
    "        print(\"X%d = dataset['%s'].values\" % (i,table_ordered[i][2]))\n",
    "\n",
    "    print('\\n')\n",
    "        \n",
    "    for i in range(index2):\n",
    "        print(\"X%d,\" % i)\n",
    "    \n",
    "    \"\"\"\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_Global(dataset):\n",
    "    \n",
    "    # On dresse la liste des variables explicatives qu'on souhaite inclure\n",
    "    # Variables Quantitatives\n",
    "    X1 = dataset.JP_Sales.values\n",
    "    X2 = dataset.Critic_Count.values\n",
    "    X3 = dataset.Critic_Score.values\n",
    "    X4 = dataset.Year_of_Release.values\n",
    "    X5 = dataset.Other_Sales.values\n",
    "    X6 = dataset.User_Score.values\n",
    "    X7 = dataset.User_Count.values\n",
    "    \n",
    "    # Platform\n",
    "    X8_4 = dataset.Platform_SNES.values\n",
    "    X8_5 = dataset.Platform_X360.values\n",
    "    X8_7 = dataset.Platform_2600.values\n",
    "    X8_8 = dataset.Platform_Wii.values\n",
    "    X8_10 = dataset.Platform_N64.values\n",
    "    X8_11 = dataset.Platform_XOne.values\n",
    "    X8_17 = dataset.Platform_GBA.values\n",
    "    X8_18 = dataset.Platform_GC.values\n",
    "    X8_19 = dataset.Platform_DS.values\n",
    "    X8_20 = dataset.Platform_XB.values\n",
    "    X8_25 = dataset.Platform_SAT.values\n",
    "\n",
    "\n",
    "    # Genre    \n",
    "    X9_1 = dataset.Genre_Platform.values\n",
    "    X9_2 = dataset.Genre_Shooter.values\n",
    "    X9_3 = dataset.Genre_Racing.values\n",
    "    X9_4 = dataset.Genre_Sports.values\n",
    "    X9_5 = dataset['Genre_Role-Playing'].values\n",
    "    X9_11 = dataset.Genre_Strategy.values\n",
    "    \n",
    "    # Rating\n",
    "    X10_4 = dataset.Rating_E.values\n",
    "    \n",
    "    # Publisher\n",
    "    X11_1 = dataset['Publisher_Nintendo'].values\n",
    "    X11_2 = dataset['Publisher_Microsoft Game Studios'].values\n",
    "    X11_6 = dataset['Publisher_Take-Two Interactive'].values\n",
    "    X11_8 = dataset['Publisher_Electronic Arts'].values\n",
    "    X11_9 = dataset['Publisher_Activision'].values\n",
    "    X11_10 = dataset['Publisher_Warner Bros. Interactive Entertainment'].values\n",
    "    X11_15 = dataset['Publisher_Disney Interactive Studios'].values\n",
    "    X11_18 = dataset['Publisher_Ubisoft'].values\n",
    "    X11_19 = dataset['Publisher_THQ'].values\n",
    "    X11_25 = dataset['Publisher_Konami Digital Entertainment'].values\n",
    "    \n",
    "    # Developer\n",
    "    X12_20 = dataset['Developer_Ubisoft'].values\n",
    "    \n",
    "    X13 = dataset['Complete_Data'].values   \n",
    "    \n",
    "    \n",
    "    # Par tattonnement on arrive a\n",
    "    X = np.array([X1,X1**2,X1*X5,X1*X4,X5*X4,X5**2,X4,X2,X3,X6,X7,X7**2,\n",
    "                  X8_4,\n",
    "                  X8_5,X8_7+X8_8+X8_10+X8_11,X8_17+X8_18+X8_19,X8_20,\n",
    "                  X8_25,\n",
    "                  X9_1,X9_2,X9_3+X9_4,X9_5,X9_11,\n",
    "                  X10_4,\n",
    "                  X11_1+X11_2,X11_6+X11_8+X11_9+X11_10+X11_15,X11_18+X11_19,X11_25,\n",
    "                  X12_20,\n",
    "                  X13]).T\n",
    "    \n",
    "    \n",
    "    # On transforme pour moyenne = 0 et variance = 1\n",
    "    X_std = scaler(X)\n",
    "    \n",
    "    # On ajoute une colonne de 1\n",
    "    Ones = np.array([np.ones(len(dataset))]).T\n",
    "    X_std = np.concatenate((Ones,X_std),axis = 1)\n",
    "    \n",
    "    return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev (Global) : 0.7767\n",
      "RMSE (Global) : 0.3848\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y1 = df_train_clean.Global_Sales.values\n",
    "X1 = createX_Global(df_train_clean)\n",
    "B1 = ridge_regression(Y1,X1,1)\n",
    "\n",
    "# Clip to min 0\n",
    "global_data = np.dot(X1,B1)\n",
    "global_data = global_data.clip(min=0)\n",
    "\n",
    "print(\"R2_prev (Global) : %.4f\" % (R2_prev(Y1,global_data,X1)))\n",
    "print(\"RMSE (Global) : %.4f\" % (RMSE(Y1,global_data)))\n",
    "print(\"\\n\")\n",
    "        \n",
    "#R2_prev (Global) : 0.7883\n",
    "#RMSE (Global) : 0.3687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of B displayed = 0.220 %\n",
      "Index \t B_i % \t Name \t (l = 3.00  -  minB = 0.005 %)\n",
      "------------------------------------------\n",
      "1608. \t 0.090 \t Other_Sales \n",
      "1607. \t 0.072 \t JP_Sales \n",
      "580. \t 0.011 \t Developer_Good Science Studio \n",
      "965. \t 0.009 \t Developer_Nintendo \n",
      "1636. \t 0.007 \t Platform_X360 \n",
      "1634. \t 0.007 \t Platform_Wii \n",
      "2199. \t 0.006 \t User_Count \n",
      "245. \t 0.006 \t Developer_Bungie Software \n",
      "1. \t 0.006 \t Critic_Score \n",
      "341. \t 0.005 \t Developer_DMA Design \n"
     ]
    }
   ],
   "source": [
    "cofficientTrier(df_train_clean,\n",
    "                df_train_clean.Global_Sales.values,\n",
    "                3,\n",
    "                0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_NA(dataset):\n",
    "    \n",
    "    # Variables Quantitatives\n",
    "    X1 = dataset.JP_Sales.values\n",
    "    X2 = dataset.Critic_Count.values\n",
    "    X3 = dataset.Critic_Score.values\n",
    "    X4 = dataset.Year_of_Release.values\n",
    "    X5 = dataset.Other_Sales.values\n",
    "    X6 = dataset.User_Score.values\n",
    "    X7 = dataset.User_Count.values\n",
    "    \n",
    "    # Platform\n",
    "    X8_4 = dataset.Platform_2600.values\n",
    "    X8_5 = dataset.Platform_X360.values\n",
    "    X8_6 = dataset.Platform_N64.values\n",
    "    X8_7 = dataset.Platform_Wii.values\n",
    "    X8_9 = dataset.Platform_XOne.values\n",
    "    X8_11 = dataset.Platform_SNES.values\n",
    "    X8_16 = dataset.Platform_GC.values\n",
    "    X8_18 = dataset.Platform_XB.values\n",
    "    X8_26 = dataset.Platform_SAT.values\n",
    "\n",
    "    # Genre    \n",
    "    X9_1 = dataset.Genre_Platform.values\n",
    "    X9_9 = dataset['Genre_Role-Playing'].values\n",
    "    \n",
    "    # Publisher\n",
    "    X11_1 = dataset['Publisher_Nintendo'].values\n",
    "    X11_2 = dataset['Publisher_Microsoft Game Studios'].values\n",
    "    X11_7 = dataset['Publisher_Activision'].values\n",
    "    X11_11 = dataset['Publisher_Warner Bros. Interactive Entertainment'].values\n",
    "    \n",
    "    \n",
    "    X12 = dataset['Complete_Data'].values  \n",
    "\n",
    "    X = np.array([X1**2,X1,X1*X5,X5,X1**2*X4**2,X4,X5**2,(X3**9)*X2,\n",
    "                  X8_4+X8_5+X8_6+X8_7+X8_9,X8_11,X8_16+X8_18,X8_26,\n",
    "                  X9_1,X9_9,\n",
    "                  X11_1+X11_2,X11_7+X11_11,\n",
    "                  X12]).T\n",
    "    \n",
    "    # On transforme pour moyenne = 0 et variance = 1\n",
    "    X_std = scaler(X)\n",
    "    \n",
    "    # On ajoute une colonne de 1\n",
    "    Ones = np.array([np.ones(len(dataset.JP_Sales))]).T\n",
    "    \n",
    "    X_std = np.concatenate((Ones,X_std),axis = 1)\n",
    "    \n",
    "    return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA R2_prev : 0.464\n",
      "RMSE (NA) : 0.2570\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y2 = df_train_clean.NA_Sales.values\n",
    "X2 = createX_NA(df_train_clean)\n",
    "B2 = ridge_regression(Y2,X2,3)\n",
    "\n",
    "# Clip to min 0\n",
    "na_data = np.dot(X2,B2)\n",
    "na_data = na_data.clip(min=0)\n",
    "\n",
    "print(\"NA R2_prev : %.3f\" % (R2_prev(Y2,na_data,X2)))\n",
    "print(\"RMSE (NA) : %.4f\" % (RMSE(Y2,na_data)))\n",
    "print(\"\\n\")\n",
    "\n",
    "#NA R2_prev : 0.602\n",
    "#RMSE (NA) : 0.2246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of B displayed = 0.157 %\n",
      "Index \t B_i % \t Name \t (l = 3.00  -  minB = 0.005 %)\n",
      "------------------------------------------\n",
      "1608. \t 0.062 \t Other_Sales \n",
      "1607. \t 0.041 \t JP_Sales \n",
      "580. \t 0.014 \t Developer_Good Science Studio \n",
      "1636. \t 0.009 \t Platform_X360 \n",
      "245. \t 0.007 \t Developer_Bungie Software \n",
      "1634. \t 0.007 \t Platform_Wii \n",
      "1. \t 0.006 \t Critic_Score \n",
      "965. \t 0.005 \t Developer_Nintendo \n",
      "688. \t 0.005 \t Developer_Infinity Ward \n"
     ]
    }
   ],
   "source": [
    "cofficientTrier(df_train_clean,\n",
    "                df_train_clean.NA_Sales.values,\n",
    "                3,\n",
    "                0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Processing du jeu de donnees test\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On cree nos matrices de variables explicatives\n",
    "X1_test = createX_Global(df_test_clean).copy()\n",
    "X2_test = createX_NA(df_test_clean).copy()\n",
    "\n",
    "# On genere nos predictions\n",
    "global_data_test = np.dot(X1_test,B1)\n",
    "na_data_test = np.dot(X2_test,B2)\n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "global_data_test = global_data_test.clip(min=0)  \n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "na_data_test = na_data_test.clip(min=0)\n",
    "\n",
    "# On vient prendre le dataframe comme canva\n",
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "# On assigne nos predictions aux colonnes\n",
    "df_test_estimated['Global_Sales'] = global_data_test\n",
    "df_test_estimated['NA_Sales'] = na_data_test\n",
    "\n",
    "# On sauvegarde nos predictions\n",
    "df_test_estimated.to_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
