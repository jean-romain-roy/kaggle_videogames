{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Regression de Ridge (L2) par methode des moindres carres permettant la penalisation du surapprentissage.\n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : matrice contenant nos variables explicatives (dimension : n x p)\n",
    "    l : facteur qui permet de diminuer l'amplitude des coefficients de regression\n",
    "    minY : borne inférieur appliquer sur les predictions\n",
    "    maxY : borne supérieur appliquer sur les predictions\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative       \n",
    "        \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = Matrices de nos coefficiants de regression (dimension (p+1) x 1)\n",
    "    Y_estime = Nouvelles predictions avec les coefficiants B\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def ridge_regression(y,x,l,minY,maxY):\n",
    "    \n",
    "    # Nombre d'observations\n",
    "    n = len(x)\n",
    "    \n",
    "    # Nombre de variable explicative\n",
    "    p = len(x.T)\n",
    "    \n",
    "    # Colonne de 1\n",
    "    Ones = np.array([np.ones(n)]).T\n",
    "    \n",
    "    # On l'emboite a notre matrice x\n",
    "    x_withOne = np.concatenate((Ones,x),axis = 1)    \n",
    "    \n",
    "    # Matrice identite de taille p+1\n",
    "    identi = np.identity(p+1) \n",
    "    identi[0][0] = 0 # on met un zero vis a vis le coeff b0 qui est l'ordonnee a l'origine\n",
    "    identi = np.dot(l,identi)\n",
    "    \n",
    "    # On multiplie X par soi meme\n",
    "    x2_withOne = np.dot(x_withOne.T,x_withOne)\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance avec un biais de penalite\n",
    "    C = np.linalg.inv(x2_withOne + identi)\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(y,np.dot(x_withOne,C))\n",
    "    \n",
    "    # On calcule les predictions\n",
    "    Y_estime = np.dot(x_withOne,B)\n",
    "    \n",
    "    # On borne nos prediction\n",
    "    Y_estime_borne = Y_estime.clip(minY,maxY)\n",
    "    \n",
    "    return B, Y_estime_borne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Fonction permettant de transformer une matrice pour que ses colonnes aient une moyenne = 0 et une variance = 1\n",
    "\n",
    "Argument:\n",
    "    dataset : le jeu de donnees a transformer\n",
    "    \n",
    "Retourne :\n",
    "    dataset_std : le jeu de donnees transforme\n",
    "\n",
    "\"\"\"\n",
    "def scaler(dataset):\n",
    "    \n",
    "    # On calcule la moyenne pour chaque colonne\n",
    "    u = np.array([np.mean(dataset, axis=0)])\n",
    "    \n",
    "    # On soustrait les colonnes du jeu de donnees par ses moyennes\n",
    "    dataset_std = dataset - u\n",
    "    \n",
    "    # On calcule la variance pour chaque colonne\n",
    "    sigma = np.array([np.std(dataset_std, axis=0)])\n",
    "    \n",
    "    # On divise les colonnes du jeu de donnees par ses variances\n",
    "    dataset_std = dataset_std/sigma\n",
    "    \n",
    "    # Si contient des NaN cause par une division par 0 (si la variance etait de 0)\n",
    "    if(np.isnan(dataset_std).any()):\n",
    "        print(\"Colonne de variance = 0, contient des NaN\") # On affiche le message d'erreur\n",
    "        \n",
    "    \n",
    "    return dataset_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "L'algorithme R2_prev implemente une validation croise sur l'ensemble du jeu de donnees fournis\n",
    "\n",
    "Arguments:\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    X : Nos variables explicatives\n",
    "    \n",
    "\n",
    "\n",
    "Retourne:\n",
    "\n",
    "    R2_prev : Une mesure bornee entre [-inf, 1] qui represente le pouvoir predictif de nos estimations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def R2_prev(Y,W,X):\n",
    "    \n",
    "    # On multiplie X par soi meme\n",
    "    X2 = np.dot(X.T,X)  \n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(X2)\n",
    "    \n",
    "    # Hat Matrix (X*B = H*Y)\n",
    "    H = np.dot(np.dot(X,C),X.T)\n",
    "    \n",
    "    # We are only interested in the (i,i) values\n",
    "    H = np.diagonal(H)\n",
    "    \n",
    "    # Mean of Y\n",
    "    y_S = np.sum(Y)/float(len(Y))\n",
    "    \n",
    "    num = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        num += ((Y[i] - W[i])/float(1 - H[i]))**2\n",
    "\n",
    "    denom = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        denom += (Y[i] - y_S)**2\n",
    "    \n",
    "    R2_prev = (1 - num/denom)\n",
    "    \n",
    "    return R2_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Selon le document MTH3302_CriteresProjet.pdf nous sommes evalues par notre root mean squared error (RMSE).\n",
    "On trouve ici son implementation.\n",
    "\n",
    "Arguments :\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    \n",
    "    \n",
    "Retourne:\n",
    "    rmse : L'erreur moyenne de nos predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RMSE(Y,W):\n",
    "\n",
    "    n = len(Y)\n",
    "\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += (Y[i] - W[i])**2\n",
    "        \n",
    "    rmse = total/float(n)\n",
    "        \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous avons une fonction qui la tranforme en table binaire \n",
    "avec un one bit encoder. \n",
    "\n",
    "    Disons que la variable explicative peut prendre 4 valeurs {Bleu, Vert, Jaune, Rouge},\n",
    "        \n",
    "          ID        X1\n",
    "        ----------------\n",
    "          1        Bleu\n",
    "          2        Bleu\n",
    "          3        Vert\n",
    "          4        Jaune\n",
    "          5        Vert\n",
    "          6        Rouge          \n",
    "         ...\n",
    "    \n",
    "    Suite a un encodage en 1 bit notre variable explicative X1 devient,\n",
    "    \n",
    "          ID        Bleu        Vert        Jaune        Rouge\n",
    "        -------------------------------------------------------\n",
    "          1          1           0            0            0\n",
    "          2          1           0            0            0\n",
    "          3          0           1            0            0\n",
    "          4          0           0            1            0\n",
    "          5          0           1            0            0\n",
    "          6          0           0            0            1\n",
    "                                ...\n",
    "                                \n",
    "\n",
    "Nous nous basons sur la fonction get_dummies() de la librairie Panda pour faire ceci.\n",
    "\n",
    "\n",
    "Arguments,\n",
    "\n",
    "    trainSet : le jeu de donnees de training\n",
    "    testSet : le jeu de donnees de test\n",
    "    varName : la variable qualitative que nous souhaitons transformer en tableau binaire\n",
    "    \n",
    "    \n",
    "Retourne, \n",
    "    trainSet_new : le jeu de donnees de training ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "    testSet_new : le jeu de donnees de test ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def qualiToBinary(trainSet, testSet, varName):\n",
    "    \n",
    "    # Genere la table binaire de la variable qualitative\n",
    "    trainVar_binary = pd.get_dummies(trainSet[varName],prefix=varName)\n",
    "    testVar_binary = pd.get_dummies(testSet[varName],prefix=varName)\n",
    "    \n",
    "    # On convertit nos tableaux binaires en Dataframe\n",
    "    trainVar_binary = pd.DataFrame(trainVar_binary)\n",
    "    testVar_binary = pd.DataFrame(testVar_binary)\n",
    "    \n",
    "    # On enleve la variable qualitative de nos jeux de donnees\n",
    "    trainSet_new = trainSet.drop([varName], axis=1)\n",
    "    testSet_new = testSet.drop([varName], axis=1)   \n",
    "\n",
    "    # On ajoute les nouvelles colonnes a nos jeux de donnees\n",
    "    trainSet_new = pd.concat([trainSet_new,trainVar_binary],axis=1)\n",
    "    testSet_new = pd.concat([testSet_new,testVar_binary],axis=1)\n",
    "    \n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees test\n",
    "    missing_categories = set(trainSet_new) - set(testSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        testSet_new[c] = 0\n",
    "\n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees training\n",
    "    missing_categories = set(testSet_new) - set(trainSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        trainSet_new[c] = 0\n",
    "\n",
    "\n",
    "    # On aligne nos jeux de donnees pour que les memes colonnes soient aux memes endroits\n",
    "    trainSet_new, testSet_new = trainSet_new.align(testSet_new, axis=1)\n",
    "    \n",
    "    # On retourne les jeux de donnees\n",
    "    return trainSet_new, testSet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement des données manquantes\n",
    "\n",
    "strat_imputation = [\"drop_na\", \"mean\", \"median\", \"most_frequent\", \"hot_deck\", \"cold_deck\"]\n",
    "\n",
    "def impute_data(data, nom_colonne, method = \"drop_na\"):\n",
    "    \"\"\"\n",
    "    On remplace les valeurs manquantes dans la colonne sélectionnée suivant l'une des stratégie ci-dessous:\n",
    "    - drop_na :  On supprime simplement les lignes avec des valeurs manquantes\n",
    "    - moyenne/médiane/mode : on remplace les valeurs manquantes par la moyenne, médiane ou mode de la colonne respectivement\n",
    "    - hot_deck : on cherche des données avec des caractéristiques similaires à la ligne avec la valeur manquante et\n",
    "                  on lui donne une valeur aléatoire de celles-ci\n",
    "    - cold_deck : on cherche des données avec des caractéristiques similaires à la ligne avec la valeur manquante et\n",
    "                  on lui donne une valeur particulière parmi celles-ci\n",
    "\n",
    "    \n",
    "    retourne la base de données imputée\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"drop_na\":\n",
    "        return data.dropna(subset = [nom_colonne])\n",
    "    \n",
    "    if method == \"mean\" or method == \"median\" or method == \"most_frequent\":\n",
    "        from sklearn.preprocessing import Imputer\n",
    "        imputer = Imputer(strategy = method)\n",
    "        imputed = data.copy()\n",
    "        imputed[nom_colonne] = imputer.fit_transform(data[[nom_colonne]])\n",
    "        return imputed\n",
    "    \n",
    "    if method == \"hot_deck\" :\n",
    "        #on itère sur la colonne, et si on trouve une valeur manquante, on cherche toutes les observations avec les\n",
    "        # ... mêmes valeurs de platform et genre ainsi qu'une valeur proche de other_sales. Puis on choisis une valeur\n",
    "        # ... aléatoire parmi celles-ci pour imputer notre valeur manquante.\n",
    "        imputed = data.copy()\n",
    "        for i in range(1,len(imputed.values)):\n",
    "            try:\n",
    "                if np.isnan(imputed.at[i, nom_colonne]):\n",
    "                    platform = imputed.at[i, 'Platform']\n",
    "                    genre = imputed.at[i, 'Genre']\n",
    "                    other_sales = imputed.at[i, 'Other_Sales']\n",
    "                    A = imputed.loc[(imputed[nom_colonne].notna()) & (imputed['Platform'] == platform) & (imputed['Genre'] == genre) & (imputed['Other_Sales'] < other_sales + 0.1) & (imputed['Other_Sales'] > other_sales - 0.1)]\n",
    "                    if len(A) == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        imputed.at[i, nom_colonne] = np.random.choice(A[nom_colonne])\n",
    "            except:\n",
    "                continue\n",
    "        imputed = imputed.dropna(subset = [nom_colonne])\n",
    "        return imputed\n",
    "    \n",
    "    if method == \"cold_deck\":\n",
    "        #même méthode que pour le hot_deck, sauf que cette fois_ci on ne choisis pas aléatoirement pour ne pas\n",
    "        #... ajouter de la variabilité au modèle. On choisit de manière déterministe, dans notre cas la première\n",
    "        imputed = data.copy()\n",
    "        for i in range(1,len(imputed.values)):\n",
    "            if np.isnan(imputed.at[i, nom_colonne]):\n",
    "                platform = imputed.at[i, 'Platform']\n",
    "                genre = imputed.at[i, 'Genre']\n",
    "                other_sales = imputed.at[i, 'Other_Sales']\n",
    "                A = imputed.loc[(imputed[nom_colonne].notna()) & (imputed['Platform'] == platform) & (imputed['Genre'] == genre) & (imputed['other_sales'] < other_sales + 0.05) & (imputed['other_sales'] > other_sales - 0.05)]\n",
    "                if len(A) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    imputed.at[i, nom_colonne] = A.values[0]\n",
    "        imputed = imputed.dropna(subset = [nom_colonne])\n",
    "        return imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies\n",
    "import numpy as np # calcul matriciel\n",
    "import pandas as pd # structure des donnees\n",
    "import matplotlib.pyplot as plt # graphiques\n",
    "\n",
    "# Chemin vers les jeux de donnees en format csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# On importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)\n",
    "\n",
    "# On enleve la colonne Name qui ne sert pas a l'analyse\n",
    "df_train = df_train.drop(['Name'],axis=1)\n",
    "\n",
    "\n",
    "# --- Variables Explicatives ---\n",
    "\n",
    "#    Name : Nom du jeu\n",
    "#    Platform : Console sur laquelle le jeu fonctionne\n",
    "#    Year_of_Release : Année de sortie du jeu\n",
    "#    Genre\n",
    "#    Publisher\n",
    "#    JP_Sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "#    Other_Sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "#    Critic_Score : Score donné par Metacritic\n",
    "#    Critic_Count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "#    User_Score : Score donné par les usagers de Metacritic\n",
    "#    User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "#    Developer : Compagnie créatrice du jeu\n",
    "#    Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "\n",
    "# --- Variables d'Interet ---\n",
    "\n",
    "#    NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "#    Global_Sales : Nombre de ventes total du jeu en millions d’unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_Release : 232\n",
      "Genre : 2\n",
      "Publisher : 49\n",
      "Critic_Score : 7186\n",
      "Critic_Count : 7186\n",
      "User_Score : 7653\n",
      "User_Count : 7653\n",
      "Developer : 5556\n",
      "Rating : 5677\n",
      "\n",
      "\n",
      "Year_of_Release : 35\n",
      "Publisher : 4\n",
      "Critic_Score : 1292\n",
      "Critic_Count : 1292\n",
      "User_Score : 1370\n",
      "User_Count : 1370\n",
      "Developer : 969\n",
      "Rating : 994\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on change les NaN grace a une technique d'imputation\n",
    "\n",
    "\"\"\"\n",
    "for i in df_train:\n",
    "    if(df_train[i].isna().sum() > 0):\n",
    "        print(\"%s : %d\" % (i,df_train[i].isna().sum()))\n",
    "        \n",
    "print('\\n')\n",
    "\n",
    "for i in df_test:\n",
    "    if(df_test[i].isna().sum() > 0):\n",
    "        print(\"%s : %d\" % (i,df_test[i].isna().sum()))\n",
    "\n",
    "df_train = impute_data(df_train, 'Year_of_Release', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Genre', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Publisher', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Critic_Score', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Critic_Count', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'User_Score', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'User_Count', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Developer', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Rating', 'hot_deck').copy()\n",
    "\n",
    "df_test = impute_data(df_test, 'Year_of_Release', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Publisher', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Critic_Score', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Critic_Count', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'User_Score', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'User_Count', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Developer', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Rating', 'hot_deck').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories Platform (train) : 17\n",
      "Nbr. of categories Platform (test) : 17 \n",
      "\n",
      "Nbr. of categories Genre (train) : 12\n",
      "Nbr. of categories Genre (test) : 12 \n",
      "\n",
      "Nbr. of categories Publisher (train) : 481\n",
      "Nbr. of categories Publisher (test) : 122 \n",
      "\n",
      "Nbr. of categories Developer (train) : 1565\n",
      "Nbr. of categories Developer (test) : 500 \n",
      "\n",
      "Nbr. of categories Rating (train) : 8\n",
      "Nbr. of categories Rating (test) : 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on transforme nos variables qualitatives en tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories Platform (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories Platform (test) : %d \\n\" %(df_test.Platform.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Platform') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories Genre (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories Genre (test) : %d \\n\" %(df_test.Genre.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Genre') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories Publisher (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories Publisher (test) : %d \\n\" %(df_test.Publisher.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Publisher') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories Developer (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories Developer (test) : %d \\n\" %(df_test.Developer.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Developer') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories Rating (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories Rating (test) : %d \\n\" %(df_test.Rating.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Rating') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on ajoute de nouvelles colonnes qui sont des combinaisons non-lineaires \n",
    "\n",
    "des autres colonnes ou de toute nouvelles informations.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On ajoute une colonne qui comptabilise le nombre de NaN pour chaque jeu video\n",
    "nbrOfNaN_train = ~(df_train.T.iloc[:].isna().sum().astype(bool))\n",
    "df_train['Contains_NaN'] = nbrOfNaN_train.astype(np.uint8)\n",
    "\n",
    "nbrOfNaN_test = ~(df_test.T.iloc[:].isna().sum().astype(bool))\n",
    "df_test['Contains_NaN'] = nbrOfNaN_test.astype(np.uint8)\n",
    "\n",
    "df_train['JP_Sales2'] = df_train.JP_Sales**2\n",
    "df_test['JP_Sales2'] = df_test.JP_Sales**2\n",
    "\n",
    "df_train['Other_Sales2'] = df_train.Other_Sales**2\n",
    "df_test['Other_Sales2'] = df_test.Other_Sales**2\n",
    "\n",
    "df_train['JP_Sales_Other_Sales'] = df_train.Other_Sales*df_train.JP_Sales\n",
    "df_test['JP_Sales_Other_Sales'] = df_test.Other_Sales*df_test.JP_Sales\n",
    "\n",
    "df_train['Other_Sales_Year_of_Release'] = df_train.Other_Sales*df_train.Year_of_Release\n",
    "df_test['Other_Sales_Year_of_Release'] = df_test.Other_Sales*df_test.Year_of_Release\n",
    "\n",
    "df_train['JP_Sales_Year_of_Release'] = df_train.JP_Sales*df_train.Year_of_Release\n",
    "df_test['JP_Sales_Year_of_Release'] = df_test.JP_Sales*df_test.Year_of_Release\n",
    "\n",
    "df_train['JP_Sales_Year2_of_Release2'] = df_train.JP_Sales**2*df_train.Year_of_Release**2\n",
    "df_test['JP_Sales_Year2_of_Release2'] = df_test.JP_Sales**2*df_test.Year_of_Release**2\n",
    "\n",
    "df_train['Critic_Score9_Critic_Count'] = df_train.Critic_Score**9*df_train.Critic_Count\n",
    "df_test['Critic_Score9_Critic_Count'] = df_test.Critic_Score**9*df_test.Critic_Count\n",
    "\n",
    "df_train['Critic_Score12_Critic_Count'] = df_train.Critic_Score**12*df_train.Critic_Count\n",
    "df_test['Critic_Score12_Critic_Count'] = df_test.Critic_Score**12*df_test.Critic_Count\n",
    "\n",
    "df_train['Critic_Score_Critic_Count'] = df_train.Critic_Score*df_train.Critic_Count\n",
    "df_test['Critic_Score_Critic_Count'] = df_test.Critic_Score*df_test.Critic_Count\n",
    "\n",
    "df_train['User_Score_User_Count'] = df_train.User_Score*df_train.User_Count\n",
    "df_test['User_Score_User_Count'] = df_test.User_Score*df_test.User_Count\n",
    "\n",
    "df_train['User_Score2'] = df_train.User_Score**2\n",
    "df_test['User_Score2'] = df_test.User_Score**2\n",
    "\n",
    "df_train['User_Count2'] = df_train.User_Count**2\n",
    "df_test['User_Count2'] = df_test.User_Count**2\n",
    "\n",
    "df_train['Critic_Count2'] = df_train.Critic_Count**2\n",
    "df_test['Critic_Count2'] = df_test.Critic_Count**2\n",
    "\n",
    "df_train['Critic_Score2'] = df_train.Critic_Score**2\n",
    "df_test['Critic_Score2'] = df_test.Critic_Score**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une matrice de nos variables\n",
    "X_train = df_train.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "X_test = df_test.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "\n",
    "# On isole nos variables d'interet\n",
    "Y1 = df_train.Global_Sales.values\n",
    "Y2 = df_train.NA_Sales.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean-romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne de variance = 0, contient des NaN\n",
      "Colonne de variance = 0, contient des NaN\n"
     ]
    }
   ],
   "source": [
    "# On transforme nos variables pour moyenne = 0 et var = 1\n",
    "X_train_std = scaler(X_train.values)\n",
    "X_test_std = scaler(X_test.values)\n",
    "\n",
    "# On enleve les colonnes ou nous avons des NaN (train)\n",
    "columnNaN = ~np.all(np.isnan(X_train_std), axis=0)\n",
    "X_train_std = X_train_std[:,columnNaN]\n",
    "X_test_std = X_test_std[:,columnNaN]\n",
    "\n",
    "# On enleve les colonnes ou nous avons des NaN (test)\n",
    "columnNaN = ~np.all(np.isnan(X_test_std), axis=0)\n",
    "X_train_std = X_train_std[:,columnNaN]\n",
    "X_test_std = X_test_std[:,columnNaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, minY = 0.058\n",
      "Global Sales, RMSE = 0.227 \n",
      "\n",
      "NA Sales, minY = 0.022\n",
      "NA Sales, RMSE = 0.122\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametre 1 (Global_Sales) - plancher des predictions\n",
    "best_RMSE = 1\n",
    "best_minY1 = 0\n",
    "\n",
    "maxY = np.max(Y1)\n",
    "l = 0.5\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minY = 0.05 + 0.001*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y1,X_train_std,l,minY,maxY)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y1,Y_est)\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_minY1 = minY\n",
    "\n",
    "        \n",
    "print(\"Global Sales, minY = %.3f\" % best_minY1)\n",
    "print(\"Global Sales, RMSE = %.3f \\n\" % best_RMSE)\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparametre 1 (NA_Sales) - plancher des predictions\n",
    "best_RMSE = 1\n",
    "best_minY2 = 0\n",
    "\n",
    "maxY = np.max(Y2)\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minY = 0.01 + 0.001*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y2,X_train_std,l,minY,maxY)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y2,Y_est)\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_minY2 = minY\n",
    "\n",
    "        \n",
    "print(\"NA Sales, minY = %.3f\" % best_minY2)\n",
    "print(\"NA Sales, RMSE = %.3f\" % best_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, maxY = 82.5407\n",
      "NA Sales, maxY = 41.3598\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametre 2 (Global_Sales) - plafond des predictions\n",
    "best_maxY1 = np.max(Y1)\n",
    "print(\"Global Sales, maxY = %.4f\" % best_maxY1)\n",
    "\n",
    "# Hyperparametre 2 (NA_Sales) - plafond des predictions\n",
    "best_maxY2 = np.max(Y2)\n",
    "print(\"NA Sales, maxY = %.4f\" % best_maxY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, minl = 0.0000\n",
      "Global Sales, RMSE = 0.2267 \n",
      "\n",
      "NA Sales, minl = 0.0000\n",
      "NA Sales, RMSE = 0.1214 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+YXVV97/H3h9BgI0ZaMioQMkEbf4BC0DFqW0EQ24BtgJaSYBBDqal40Sq2FZter8VLq1D70F6xMlqKYAqWADGVcrk10itPJV4mEtGEEgJCCNEmqEhtBIz53D/2Gtg5zGTOhNlz5sfn9Tznmb3XXnuf7w5Mvllr7b2WbBMRETHS9ul0ABERMTElwURERCOSYCIiohFJMBER0YgkmIiIaEQSTERENCIJJqJNkq6U9D/brGtJv7SX3/OApBP25twhrtt2/BEjIQkmopC0SNLXJf2XpG1l+92S1OnY+kmaKel6SY9I+pGkb0ta0um4IgaSBBMBSPoA8NfAJcCLgBcC7wJ+BZjawdBaXQ08BHQDBwJvB/6joxFFDCIJJiY9Sc8HLgTebXuF7f905U7bi20/Mch575S0SdIPJK2SdHBLlZMk3V9aG5dI2qec9xJJX5H0/XJsuaQD2gz3tcCVtv/L9s4S4821mK6T9L3SuvmqpCP2cN+/IWmdpEclfU3SkbVjH5T0sKT/lHSPpDe3GV/EU5JgIuANwH7AF9s9QdLxwF8ApwMHAQ8C17ZUOxXoAV4NnAz8bv/p5dyDgVcAhwIfafOr1wCXle68WQMcvxmYA7wA+AawfJD4jwauAH6fqiV0ObBK0n6SXgacB7zW9vOAXwceaDO+iKckwUTADOAR2zv7C8q/6B+V9BNJxwxwzmLgCtvfKC2cDwFvkDS7Vufjtn9gezNwKXAGgO1Ntv/F9hO2twN/BRzbZqy/A9wG/HfgO6UF8tr+g7avKC2wJ6iS1lGlhdZqKXC57a/b/pntzwFPAK8HfkaVcA+X9HO2H7B9X5vxRTwlCSYCvg/MkLRvf4HtX7Z9QDk20O/JwVStlv76Py51D6nVeai2/WA5B0kvlHRt6YJ6DPg8VZIbku0f2r7A9hFU40TrgJWqTJH0MUn3les+UE4b6NrdwAdKEn1U0qNULamDbW8C3keVoLaVWFu7/yKGlAQTAbdT/ev95GGcs5XqL2kAJD2Xqqvp4VqdQ2vbs8o5AH8OGHiV7enAmVTdZsNi+xHgL6kS1y8Cb6O6hxOA5wOz+8Mb4PSHgItsH1D7TLN9Tbn2P9j+1XKPBj4+3PgikmBi0rP9KPBnwKcknSbpeZL2kTQXeO4gp10DnC1prqT9qJLG120/UKvzR5J+QdKhwB8AXyjlzwN+DPxI0iHAH7Ubq6SPS3qlpH0lPQ84F9hk+/vluk9QtaSmlZgG8xngXZJeV1o/z5X01nLvL5N0fLmvx4GfALvajTGiXxJMBGD7YuB84I+pHvv9D6qB7w8CXxug/pepxkGuB74LvARY1FLti8Baqm6sm4C/K+V/RjXw/6NSfsMwQp0G3Ag8CtxP1cJYUI5dRdUV9zCwgeqBgAHZ7gPeCXwS+CGwCVhSDu8HfAx4BPge1QMDHxpGjBEAKAuORUREE9KCiYiIRiTBREREI5JgIiKiEUkwERHRiH2HrjJxzZgxw7Nnz+50GBER48ratWsfsd01VL1JnWBmz55NX19fp8OIiBhXJD04dK10kUVEREOSYCIiohFJMBER0YgkmIiIaEQSTERENCIJJiJiMlm+HGbPhn32qX4uH3DR0xHRaIKRNL+s571J0gUDHD9f0gZJd0laLam7lM+VdLuk9eXYwto5t5VV/NZJ2ippZSl/U1mHvP/Yh5u8t4iIMaPdpLF8OSxdCg8+CHb1c+nS5pKM7UY+wBTgPuDFwFTgm8DhLXWOA6aV7XOBL5TtlwJzyvbBVNOhHzDAd1wPnFW23wR8aTgxvuY1r3FExJj1+c/b3d22VP38/OcHrjNtml2ljOozbdrAdbu7d6/X/+nuHlZYQJ/b+Du2yRbMPKqFkO63/SRwLS0rBtq+1faOsrsGmFnKN9q+t2xvBbYBu701Kmk6cDywssF7iIgYWSPd2li2DHbs2L1sx46qvNXmzQN/12Dlz1KTCeYQdl+TfAu7r1fe6hzg5tZCSfOoWkD3tRw6BVht+7Fa2RskfVPSzZKOGOhLJC2V1Cepb/v27e3cR0TE0NpJHMPpomo3cQwnacyaNXDdwcqfpTExyC/pTKAHuKSl/CDgauBs261Ltp5BtWxtv28A3baPAv4Xg7RsbPfa7rHd09U15FQ6ETGZjYfWxnCSxkUXwbRpu5dNm1aVN6GdfrS9+QBvAG6p7X8I+NAA9U4A7gZe0FI+nSppnDbAOTOo1h1/zh6+/wFgxp5izBhMxCTVqbENaeB60t5fczhxtnvvQ6DNMZgmE8y+VGuGH8bTg/xHtNQ5mqrra05L+VRgNfC+Qa79LuBzLWUv4ukloOcBm/v3B/skwURMIO3+xdnuX8jDGRBvN3EM55rDSRwjkDSGo+MJpoqBk4CNJYksK2UXAgvK9peB/wDWlc+qUn4m8NNa+Tpgbu26/wrMb/mu84D1JZGtAX55qPiSYCLGgbQ2Ri1xtGtMJJix/kmCiRjj0toYk9pNMGNikD8iJpl2B887+STVcAbEFy+G3l7o7gap+tnbW5UPVPeBB2DXrurnQHUmiCSYiBg5I/2obiefpBpO0uivP0kSR9vaaeZM1E+6yCJGUBPdWZNsbGO8IF1kETEiOtmdldbGuJYEEzFZjYfurIxtjGv9741MSj09Pe7r6+t0GBGjrz9x1Fsc06Y98y/v2bOrpNKqu7v6S7yu3brtfneMWZLW2u4Zql5aMBETyUTszopxKy2YtGBiohhOy2Cffaour1ZS1cXUbzgtmP4Yli2rEtCsWVVySeKYcNKCiZhI2mmZDGcixSbeBYGMg8RukmAixrp2B9rTnRVjTBJMRKeM9HhJns6KMSYJJqITmnj8N91ZMcYkwUR0QhPjJenOijEmCSZipLXT9dXEeAmkVRJjShJMxEhqt+urqfGSiDEk78HkPZgYSXmbPSaBMfEejKT5ku6RtEnSBQMcP1/SBkl3SVotqbuUz5V0u6T15djC2jm3SVpXPlslrWy55msl7ZR0WpP3FpNMu098tdv1lVZJTAL7NnVhSVOAy4C3AFuAOyStsr2hVu1OoMf2DknnAhcDC4EdwFm275V0MLBW0i22H7X9xtp3XA98seU7Pw78n6buKyah1tZGf7cXPDMhzJo1cAtmsK6vJJSYwJpswcwDNtm+3/aTwLXAyfUKtm+13d9HsAaYWco32r63bG8FtgFd9XMlTQeOB+otmPcA15f6ESNjOE98DfdR4YgJrMkEcwjwUG1/SykbzDnAza2FkuYBU4H7Wg6dAqy2/VipdwhwKvC3ewpK0lJJfZL6tm/fPuRNxAQ30k98pesr4imNdZENh6QzgR7g2Jbyg4CrgXfY3tVy2hnAZ2v7lwIftL1L0qDfZbsX6IVqkP/ZRx/jVrtdX8Pp9uo/NwklotEWzMPAobX9maVsN5JOAJYBC2w/USufDtwELLO9puWcGVRdcDfVinuAayU9AJwGfErSKSNzKzEhtdv1lW6viL3SZIK5A5gj6TBJU4FFwKp6BUlHA5dTJZdttfKpwI3AVbZXDHDt04Av2X68v8D2YbZn254NrADebXvlAOdGVPLEV0SjGkswtncC5wG3AHcD/2h7vaQLJS0o1S4B9geuK48d9yeg04FjgCW1R5Ln1i6/CLimqdhjnGv3keLhvuyYN+QjhiUvWuZFy4llOC8w5mXHiL0yJl60jBh1w3mkOF1fEY1KCyYtmIml3aWAI2KvpQUTE087YyvDGVeJiEYlwcT40O4sxXmkOGLMSIKJ8aHdsZWMq0SMGRmDyRjM+JCxlYgxI2MwMbFkbCVi3EmCic5q96XIjK1EjDtJMNE57Q7cQ8ZWIsahjMFkDKZz2l1eOCLGlIzBxNg3nHVWImLcSYKJzsnAfcSElgQTnZOB+4gJLQkmmtHO02EZuI+Y0MbEkskxwbS7FHH/fhJKxISUFkyMvOFMmR8RE1YSTIy8PB0WETScYCTNl3SPpE2SLhjg+PmSNki6S9JqSd2lfK6k2yWtL8cW1s65rbaM8lZJK0v5yaXuOkl9kn61yXuLPcjTYRFBgwlG0hTgMuBE4HDgDEmHt1S7E+ixfSSwAri4lO8AzrJ9BDAfuFTSAQC232h7ru25wO3ADeWc1cBRpfx3gc82dW8xhDwdFhE024KZB2yyfb/tJ4FrgZPrFWzfaru/s34NMLOUb7R9b9neCmwDuurnSpoOHA+sLPV+7KenJXguMHmnKOi0PB0WETT7FNkhwEO1/S3A6/ZQ/xzg5tZCSfOAqcB9LYdOAVbbfqxW91TgL4AXAG8d6EskLQWWAsxKl01z8nRYxKQ3Jgb5JZ0J9ACXtJQfBFwNnG27ddGPM4Br6gW2b7T9cqrk89GBvst2r+0e2z1dXV0DVYnBtDvzcUQEzbZgHgYOre3PLGW7kXQCsAw41vYTtfLpwE3AMttrWs6ZQdUFd+pAX2z7q5JeLGmG7Uee9Z3E8N5tiYig2RbMHcAcSYdJmgosAlbVK0g6GrgcWGB7W618KnAjcJXtFQNc+zTgS7Yfr53zS5JUtl8N7Ad8f4TvafLKuy0RMUyNtWBs75R0HnALMAW4wvZ6SRcCfbZXUXWJ7Q9cV3LDZtsLgNOBY4ADJS0pl1xie13ZXgR8rOUrfxs4S9JPgZ8AC2uD/vFs5d2WiBimrAeT9WDak7VbIqLIejAxsvJuS0QMUxJMtCfvtkTEMGU25Whf3m2JiGFICyYiIhqRBBMREY1Igom8oR8RjcgYzGSXN/QjoiFpwUx2eUM/IhqSBDPZ5Q39iGhIEsxkl9UnI6IhSTCTXd7Qj4iGJMFMdnlDPyIakqfIIm/oR0Qj0oKJiIhGJMFEREQjkmAiIqIRjSYYSfMl3SNpk6QLBjh+vqQNku6StFpSdymfK+l2SevLsYW1c26TtK58tkpaWcoXl7rfkvQ1SUc1eW8REbFnjQ3yS5oCXAa8BdgC3CFple0NtWp3Aj22d0g6F7gYWAjsAM6yfa+kg4G1km6x/ajtN9a+43rgi2X3O8Cxtn8o6USgF3hdU/cXERF71mQLZh6wyfb9tp8ErgVOrlewfavt/nlK1gAzS/lG2/eW7a3ANqCrfq6k6cDxwMpS72u2f9h6rUkrE1hGRIc1mWAOAR6q7W8pZYM5B7i5tVDSPGAqcF/LoVOA1bYfa/da5XpLJfVJ6tu+ffsewhnH+iewfPBBsJ+ewDJJJiJG0ZgY5Jd0JtADXNJSfhBwNXC27V0tp50BXDPAtY6jSjAfHOi7bPfa7rHd09XVNVCV8S8TWEbEGNDki5YPA4fW9meWst1IOgFYRjV+8kStfDpwE7DM9pqWc2ZQdcGd2lJ+JPBZ4ETb3x+h+xh/MoFlRIwBTbZg7gDmSDpM0lRgEbCqXkHS0cDlwALb22rlU4Ebgatsrxjg2qcBX7L9eO2cWcANwNttbxzxuxlPMoFlRIwBjSUY2zuB84BbgLuBf7S9XtKFkhaUapcA+wPXlceO+xPQ6cAxwJLaI8lza5dfxDO7xz4MHAh8qtTva+jWxr5MYBkRY4BsdzqGjunp6XFf3wTNQ8uXV2MumzdXLZeLLsp8YxExIiSttd0zVL1MdjlRZQLLiOiwMfEUWURETDxJMBER0YgkmIiIaEQSTERENGKPCUbS8bXtw1qO/VZTQUVExPg3VAvmL2vb17cc+9MRjiUiIiaQoRKMBtkeaD8iIuIpQyUYD7I90H5ERMRThnrR8sVl+hbVtin7hw1+WkRETHZDJZj6AmF/2XKsdT8iIuIpe+wis/1/6x/ga8BjwN1lP0ZbVqqMiHFiqMeUPy3piLL9fOCbwFXAnZLOGIX4oi4rVUbEODLUIP8bba8v22cDG22/CngN8MeNRhbPlJUqI2IcGSrBPFnbfguwEsD29xqLKAaXlSojYhwZKsE8Kuk3ysqTvwL8bwBJ+wI/33Rw0SIrVUbEODJUgvl9qlUp/x54X63l8mbgpiYDiwFkpcqIGEeGeopso+35tufavrJWfovtDwx1cUnzJd0jaZOkCwY4fr6kDZLukrRaUncpnyvpdknry7GFtXNuqy2jvFXSylL+8nLOE5L+cBh/BuPH4sXQ2wvd3SBVP3t7s7BYRIxJe1wyWdLf7Olk2+/dw7lTgI1UYzdbgDuAM2xvqNU5Dvi67R2SzgXeZHuhpJdWl/e9kg4G1gKvsP1oy3dcD3zR9lWSXgB0A6cAP7Q95Hs6E3rJ5IiIhozUksnvAr4N/COwleHNPzYP2GT7/hLQtVQvbj6VYGzfWqu/BjizlG+s1dkqaRvQBTyVYCRNB46neroN29uAbZLeOowYIyKiIUMlmIOA3wEWAjuBLwArWlsSgzgEeKi2vwV43R7qnwPc3FooaR4wFbiv5dApwGrbj7URS/16S4GlALMyOB4R0ZihxmC+b/vTto+jaikcAGyQ9PaRDELSmUAPcElL+UHA1cDZtne1nHYGcM1wv8t2r+0e2z1dXV17G3JERAxhqBYMAJJeTfUX+luoWhlr2zjtYeDQ2v7MUtZ67ROAZcCxtp+olU+nelJtme01LefMoOqCO7Wd+CMiYvTtMcFIuhB4K3A3cC3wIds727z2HcCcshLmw8Ai4G0t1z8auByYX8ZQ+sunAjcCV9leMcC1TwO+ZPvxNmOJiIhRNlQL5k+B7wBHlc+fS4JqsN+2jxzsRNs7JZ0H3AJMAa6wvb4krT7bq6i6xPYHrivX3Wx7AXA6cAxwoKQl5ZJLbK8r24uAj9W/T9KLgD5gOrBL0vuAw4c7RhMRESNjqMeUu/d0su0HRzyiUZTHlCMihm9EHlMeLIFI2odqTGZcJ5iIiGjOUNP1T5f0IUmflPRrqrwHuJ+qGysiImJAQ43BXA38ELgd+D3gT6jGX06pjYdEREQ8w1AJ5sVl/RckfRb4LjArT29FRMRQhppN+af9G7Z/BmxJcomIiHYM1YI5SlL/Y74Cfr7s9z+mPL3R6CIiYtwa6imyKaMVSERETCxDdZFFRETslSSYiIhoRBJMREQ0IgkmIiIakQQTERGNSIKJiIhGJMGMBcuXw+zZsM8+1c/lyzsdUUTEs9bWipbRoOXLYelS2LGj2n/wwWofYPHizsUVEfEspQXTacuWPZ1c+u3YUZVHRIxjjSYYSfMl3SNpk6QLBjh+vqQNku6StLp/gTNJcyXdLml9Obawds5tktaVz1ZJK0u5JP1N+a67JL26yXsbMZs3D688ImKcaCzBSJoCXAacCBwOnCHp8JZqdwI9ZenlFcDFpXwHcJbtI4D5wKWSDgCw/Ubbc23PpVpG4IZyzonAnPJZCvxtU/c2ombNGl55RMQ40WQLZh6wyfb9tp8ErgVOrlewfavt/v6hNcDMUr7R9r1leyuwDeiqnytpOnA8sLIUnQxc5coa4ABJBzVzayPoootg2rTdy6ZNq8ojIsaxJhPMIcBDtf0tpWww5wA3txZKmgdMBe5rOXQKsNp2/2zPw/2+sWHxYujthe5ukKqfvb0Z4I+IcW9MPEUm6UygBzi2pfwgqlU132F7V8tpZwCf3YvvWkrVhcassdINtXhxEkpETDhNtmAeBg6t7c8sZbuRdAKwDFhg+4la+XTgJmBZ6fKqnzODqgvupuF+n+1e2z22e7q6uloPR0TECGkywdwBzJF0mKSpwCJgVb2CpKOBy6mSy7Za+VTgRqoxlRUDXPs04Estq2uuAs4qT5O9HviR7e+O7C1FRES7Gusis71T0nnALcAU4Arb6yVdCPTZXgVcAuwPXCcJYLPtBcDpwDHAgZKWlEsusb2ubC8CPtbylf8MnARsonoK7eym7i0iIoYm252OoWN6enrc19fX6TAiIsYVSWtt9wxVL2/yR0REI5JgIiKiEUkwERHRiCSYiIhoRBJMREQ0IgkmIiIakQQTERGNSIKJiIhGJMFEREQjkmAiIqIRSTAREdGIJJiIiGhEEkxERDQiCSYiIhqRBBMREY1IgomIiEYkwURERCMaTTCS5ku6R9ImSRcMcPx8SRsk3SVptaTuUj5X0u2S1pdjC2vnSNJFkjZKulvSe0v5L0i6sdT/f5Je2eS9RUTEnjWWYCRNAS4DTgQOB86QdHhLtTuBHttHAiuAi0v5DuAs20cA84FLJR1Qji0BDgVebvsVwLWl/E+AdeVaZwF/3ciNRUREW5pswcwDNtm+3/aTVIng5HoF27fa3lF21wAzS/lG2/eW7a3ANqCr1DsXuND2rnJ8Wyk/HPhKKft3YLakFzZ1cxERsWdNJphDgIdq+1tK2WDOAW5uLZQ0D5gK3FeKXgIslNQn6WZJc0r5N4Hfqp3TTUlYLddbWs7t2759+zBvKSIi2jUmBvklnQn0AJe0lB8EXA2c3d9iAfYDHrfdA3wGuKKUfww4QNI64D1U3W8/a/0u2722e2z3dHV1tR6OiIgRsm+D136Yaqyk38xSthtJJwDLgGNtP1Ernw7cBCyzvaZ2yhbghrJ9I/D3ALYfA84u5wr4DnD/SN1MREQMT5MtmDuAOZIOkzQVWASsqleQdDRwObCgNpZCqX8jcJXtFS3XXQkcV7aPBTaWcw4o5wH8HvDVknQiIqIDGmvB2N4p6TzgFmAKcIXt9ZIuBPpsr6LqEtsfuK5qdLDZ9gLgdOAY4EBJS8oll9heR9UVtlzS+4EfUyUTgFcAn5NkYD3VmE5ERHSIbHc6ho7p6elxX19fp8OIiBhXJK0t4+B7NCYG+SMiYuJJgomIiEYkwURERCOSYCIiohFJMBER0YgkmIiIaEQSTERENCIJJiIiGpEEExERjUiCiYiIRiTBREREI5JgIiKiEUkwERHRiCSYJi1fDrNnwz77VD+XL+90RBERo6bJFS0nt+XLYelS2LGj2n/wwWofYPHizsUVETFK0oJpyrJlTyeXfjt2VOUREZNAowlG0nxJ90jaJOmCAY6fL2mDpLskrZbUXcrnSrpd0vpybGHtHEm6SNJGSXdLem8pf76kf5L0zXLe2U3e25A2bx5eeUTEBNNYgpE0BbgMOBE4HDhD0uEt1e4EemwfCawALi7lO4CzbB8BzAculXRAObYEOBR4ue1XANeW8v8GbLB9FPAm4BOSpjZxb22ZNWt45RERE0yTLZh5wCbb99t+kioRnFyvYPtW2/39SGuAmaV8o+17y/ZWYBvQVeqdC1xoe1c5vq3/csDzJAnYH/gBsLOpmxvSRRfBtGm7l02bVpVHREwCTSaYQ4CHavtbStlgzgFubi2UNA+YCtxXil4CLJTUJ+lmSXNK+SeBVwBbgW8Bf9CfhDpi8WLo7YXubpCqn729GeCPiEljTDxFJulMoAc4tqX8IOBq4B21ZLEf8LjtHkm/BVwBvBH4dWAdcDxVEvoXSbfZfqzlmkuBpQCzmu6uWrw4CSUiJq0mWzAPU42V9JtZynYj6QRgGbDA9hO18unATcAy22tqp2wBbijbNwJHlu2zgRtc2QR8B3h56/fZ7rXdY7unq6ur9XBERIyQJhPMHcAcSYeVwfZFwKp6BUlHA5dTJZdttfKpVMnjKtsrWq67EjiubB8LbCzbm4E3l/NfCLwMuH9E7ygiItrWWBeZ7Z2SzgNuAaYAV9heL+lCoM/2KuASqgH566qxeTbbXgCcDhwDHChpSbnkEtvrgI8ByyW9H/gx8Hvl+EeBKyV9CxDwQduPNHV/ERGxZ7Ld6Rg6pqenx319fZ0OIyJiXJG01nbPUPXyJn9ERDQiCSYiIhqRBBMREY1IgomIiEYkwURERCOSYCIiohFJMBER0YgkmIiIaEQSTERENCIJJiIiGpEEM1zLl8Ps2bDPPtXP5cs7HVFExJg0JtaDGTeWL4elS2FHWYTzwQerfci6LxERLdKCGY5ly55OLv127KjKIyJiN0kww7F58/DKIyImsSSY4RhsieWml16OiBiHkmCG46KLYNq03cumTavKIyJiN0kww7F4MfT2Qnc3SNXP3t4M8EdEDKDRBCNpvqR7JG2SdMEAx8+XtEHSXZJWS+ou5XMl3S5pfTm2sHaOJF0kaaOkuyW9t5T/kaR15fNtST+T9IsjflOLF8MDD8CuXdXPJJeIiAE19piypCnAZcBbgC3AHZJW2d5Qq3Yn0GN7h6RzgYuBhcAO4Czb90o6GFgr6RbbjwJLgEOBl9veJekFALYvAS4p3/2bwPtt/6Cp+4uIiD1rsgUzD9hk+37bTwLXAifXK9i+1Xb/c79rgJmlfKPte8v2VmAb0FXqnQtcaHtXOb5tgO8+A7hmhO8nIiKGockEcwjwUG1/SykbzDnAza2FkuYBU4H7StFLgIWS+iTdLGlOS/1pwHzg+oG+RNLScm7f9u3b276ZiIgYnjExyC/pTKCH0sVVKz8IuBo4u7/FAuwHPG67B/gMcEXL5X4T+LfBusds99rusd3T1dU1UJWIiBgBTSaYh6nGSvrNLGW7kXQCsAxYYPuJWvl04CZgme01tVO2ADeU7RuBI1suuYh0j0VEdFyTc5HdAcyRdBhVYlkEvK1eQdLRwOXA/PpYiqSpVMnjKtsrWq67EjgO+A5wLLCxdt7zS9mZ7QS4du3aRyQ9OMz76jcDeGQvzx1NiXNkJc6RlThH1mjF2d1OJdluLAJJJwGXAlOAK2xfJOlCoM/2KklfBl4FfLecstn2gtJl9vfA+trlltheJ+kAYDkwC/gx8C7b3yzft4QqWS1q7Kaevre+0k03piXOkZU4R1biHFljLc5GZ1O2/c/AP7eUfbi2fcIg530e+Pwgxx4F3jrIsSuBK/cu2oiIGEljYpA/IiImniSYvdfb6QDalDhHVuIcWYlzZI2pOBsdg4mIiMkrLZiIiGhEEkxERDQiCWYIbcwIvZ+kL5TjX5c0e/Sj3PuZq8danLV6vy3JkjryyGU7cUo6vfyZrpf0D6MdY4lhqP/usyTdKunO8t/+pA7FeYWkbZK+PchxSfqbch93SXr1GIxxcYntW5K+Jumo0Y4v8sDMAAAFJklEQVSxxLHHOGv1Xitpp6TTRiu2Z7CdzyAfqvd37gNeTDUf2jeBw1vqvBv4dNleBHxhjMZ5HDCtbJ87VuMs9Z4HfJVqAtSesRgnMIdqNvBfKPsvGKNx9gLnlu3DgQdGO87y3ccArwa+Pcjxk6jmIhTweuDrYzDGX6799z6xEzG2E2ft/42vUL0mclon4rSdFswQhpwRuux/rmyvAN4sSaMYIzyLmatHWTt/ngAfBT4OPD6awdW0E+c7gcts/xAGndW7ae3EaWB62X4+sHUU43s6CPurwJ6WzziZauYOu5oa6oAyF+GoGSpG21/r/+9N536H2vmzBHgP1YS/nfj/8ilJMHvWzozQT9WxvRP4EXDgqEQ3QAzFXs1cPQqGjLN0jRxq+6bRDKxFO3+eLwVeKunfJK2RNH/UontaO3F+BDhT0haqf82+Z3RCG7bh/j/caZ36HRqSpEOAU4G/7XQsjb7JH2NPbebqYzsdSytJ+wB/RbWo3Fi3L1U32Zuo/iX7VUmvcjXTxFhyBnCl7U9IegNwtaRX+unZyWOYJB1HlWB+tdOxDOJS4IOuFmTsaCBJMHvWzozQ/XW2SNqXqhvi+6MT3jNi6DfUzNXHujZz9SgaKs7nAa8E/rX8YrwIWCVpge2+UYuyvT/PLVR98D8FviNpI1XCuWN0QgTai/McqvWRsH27pOdQTYjY0a6TAbT1/3CnSToS+Cxwou3R/j1vVw9wbfkdmgGcJGmn7ZWjHUi6yPbsqRmhywzPi4BVLXVWAe8o26cBX3EZZRtFQ8ZZm7l6QYfGC2CIOG3/yPYM27Ntz6bq5x7t5DJknMVKqtYLkmZQdZndP5pB0l6cm4E3A0h6BfAcYCyutLcKOKs8TfZ64Ee2vzvUSaNJ0iyqpULebnvjUPU7xfZhtd+hFcC7O5FcIC2YPbK9U9J5wC08PSP0etVmhAb+jqrbYRPVwFvjMznvZZyXAPsD15V/2Wy2vWAMxtlxbcZ5C/BrkjYAPwP+aLT/RdtmnB8APiPp/VQD/ks68A8gJF1DlZBnlPGg/wH8XLmPT1OND50EbAJ2AGePwRg/TDW++qnyO7TTHZi5uI04x4xMFRMREY1IF1lERDQiCSYiIhqRBBMREY1IgomIiEYkwURERCOSYCJGmKQfj9B1PiLpD9uod2VHZ8yNGEQSTERENCIJJqIhkvYva+98o6whcnIpny3p30vLY6Ok5ZJOKBNn3itpXu0yR0m6vZS/s5wvSZ9UtQ7Ml4EX1L7zw5LukPRtSb0dmNk74ilJMBHNeRw41farqdbj+UTtL/xfAj4BvLx83kY1eeIfAn9Su8aRwPHAG4APSzqYaqbcl1Gt73IW1Tol/T5p+7W2Xwn8PPAbDd1bxJAyVUxEcwT8uaRjgF1U08+/sBz7ju1vAUhaD6y2bUnfAmbXrvFF2z8BfiLpVqo1YI4BrrH9M2CrpK/U6h8n6Y+BacAvAuuBf2rsDiP2IAkmojmLgS7gNbZ/KukBqskmAeqzWe+q7e9i99/L1rmcBp3bqcyU/CmqVUAfkvSR2vdFjLp0kUU05/nAtpJcjgO69+IaJ0t6jqQDqSY4vINqOemFkqaUVR+PK3X7k8kjkvanmt07omPSgoloznLgn0q3Vx/w73txjbuAW6nW9fio7a2SbqQal9lANR3/7QC2H5X0GeDbwPcY3bVpIp4hsylHREQj0kUWERGNSIKJiIhGJMFEREQjkmAiIqIRSTAREdGIJJiIiGhEEkxERDTi/wNp7mnV7iLX+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparametre 3 (Global_Sales) - parametre de penalisation\n",
    "nbr_ite = 30\n",
    "\n",
    "best_RMSE = 1\n",
    "best_l1 = 0\n",
    "rmse1 = np.zeros(nbr_ite)\n",
    "\n",
    "maxY = np.max(Y1)\n",
    "\n",
    "for i in range(nbr_ite):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minl = 0.05*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y1,X_train_std,minl,best_minY1,best_maxY1)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y1,Y_est)\n",
    "    rmse1[i] = rmse\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_l1 = minl\n",
    "\n",
    "        \n",
    "print(\"Global Sales, minl = %.4f\" % best_l1)\n",
    "print(\"Global Sales, RMSE = %.4f \\n\" % best_RMSE)\n",
    "\n",
    "\n",
    "# Hyperparametre 1 (NA_Sales) - parametre de penalisation\n",
    "best_RMSE = 1\n",
    "best_l2 = 0\n",
    "rmse2 = np.zeros(nbr_ite)\n",
    "\n",
    "maxY = np.max(Y2)\n",
    "\n",
    "for i in range(nbr_ite):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minl = 0.05*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y2,X_train_std,minl,best_minY2,best_maxY2)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y2,Y_est)\n",
    "    rmse2[i] = rmse\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_l2 = minl\n",
    "\n",
    "        \n",
    "print(\"NA Sales, minl = %.4f\" % best_l2)\n",
    "print(\"NA Sales, RMSE = %.4f \\n\" % best_RMSE)\n",
    "\n",
    "index = np.array(list(range(nbr_ite)))\n",
    "index = index*0.05\n",
    "\n",
    "plt.plot(index, rmse1, 'or')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Global Sales')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(index, rmse2, 'or')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('NA Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev :  -48.34795823538862\n",
      "RMSE :  0.22737505147828263\n"
     ]
    }
   ],
   "source": [
    "# Global Sales\n",
    "B1, Y_est1 = ridge_regression(Y1,X_train_std,0.5,best_minY1,best_maxY1)\n",
    "\n",
    "# Clip\n",
    "global_data = np.dot(X_train_std,np.delete(B1,0)) + B1[0]\n",
    "global_data = global_data.clip(best_minY1,best_maxY1)\n",
    "\n",
    "print(\"R2_prev : \",R2_prev(Y1,global_data,X_train_std))\n",
    "print(\"RMSE : \",RMSE(Y1,global_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029198766016137"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "l = 0.02\n",
    "R2_prev :  -48.347817314184816\n",
    "RMSE :  0.22650613448763485\n",
    "\"\"\"\n",
    "\n",
    "np.max(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev :  -53.111878455682024\n",
      "RMSE :  0.12186633950757095\n"
     ]
    }
   ],
   "source": [
    "# NA Sales\n",
    "B2, Y_est2 = ridge_regression(Y2,X_train_std,0.5,best_minY2,best_maxY2)\n",
    "\n",
    "# Clip\n",
    "na_data = np.dot(X_train_std,np.delete(B2,0)) + B2[0]\n",
    "na_data = na_data.clip(best_minY2,best_maxY2)\n",
    "\n",
    "print(\"R2_prev : \",R2_prev(Y2,na_data,X_train_std))\n",
    "print(\"RMSE : \",RMSE(Y2,na_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6592009350166297"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "l = 0.02\n",
    "R2_prev :  -53.112553000119576\n",
    "RMSE :  0.1215303737240002\n",
    "\"\"\"\n",
    "\n",
    "np.max(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Processing du jeu de donnees test\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On genere nos predictions\n",
    "global_data_test = np.dot(X_test_std,np.delete(B1,0)) + B1[0]\n",
    "na_data_test = np.dot(X_test_std,np.delete(B2,0)) + B2[0]\n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "global_data_test = global_data_test.clip(best_minY1,best_maxY1)  \n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "na_data_test = na_data_test.clip(best_minY2,best_maxY2)\n",
    "\n",
    "# On vient prendre le dataframe comme canva\n",
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "# On assigne nos predictions aux colonnes\n",
    "df_test_estimated['Global_Sales'] = global_data_test\n",
    "df_test_estimated['NA_Sales'] = na_data_test\n",
    "\n",
    "# On sauvegarde nos predictions\n",
    "df_test_estimated.to_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
