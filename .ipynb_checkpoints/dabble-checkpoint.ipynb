{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe les librairies utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chemin vers les csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# Importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "--- Variables Explicatives ---\n",
    "Name : Nom du jeu\n",
    "Platform : Console sur laquelle le jeu fonctionne\n",
    "Year of release : Année de sortie du jeu\n",
    "Genre\n",
    "Publisher\n",
    "JP_sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "Other sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "Critic_score : Score donné par Metacritic\n",
    "Critic_count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "User_Score : Score donné par les usagers de Metacritic\n",
    "User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "Developer : Compagnie créatrice du jeu\n",
    "Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "--- Variable d'interet ---\n",
    "NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "Global_Sales : Nombre de ventes total du jeu en millions d’unités\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Evaluation des predictions --- \n",
    "\n",
    "Dans le document MTH3302_CriteresProjet-1.pdf on nous informe que la precision\n",
    "de nos estimations sera evaluee avec le root mean square error (RMSE)\n",
    "\n",
    "On definit cette fonction ci-bas,\n",
    "\n",
    "    Y : Variable d'interet\n",
    "    W : Predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RMSE(Y,W):\n",
    "    \n",
    "    # Nombre d'observations\n",
    "    n = len(Y)\n",
    "    \n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += (Y[i] - W[i])**2\n",
    "    \n",
    "    mean = total/float(n)\n",
    "    \n",
    "    print(\"RMSE = %.2f\" % (mean))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous les transformons en table binaire.\n",
    "Nous nous basons sur la fonction get_dummies de la librairies Panda pour arriver a nos fins.\n",
    "\n",
    "Input,\n",
    "    trainSet : le dataframe complet contenant le jeu de donnees de training avec toutes ses colonnes\n",
    "    testSet : le dataframe complet contenant le jeu de donnees de training avec toutes ses colonnes\n",
    "    trainVar : la variable qualitative que nous souhaitons transformer en tableau de variable binaire\n",
    "    testVar : la variable qualitative que nous souhaitons transformer en tableau de variable binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def binerizedQualitativeVariable(trainSet, testSet, trainVar, testVar):\n",
    "    \n",
    "    # Generate Binary Table\n",
    "    trainVar_binary = pd.get_dummies(trainVar)\n",
    "    testVar_binary = pd.get_dummies(testVar)\n",
    "\n",
    "    # We concatenate the new columns\n",
    "    trainSet = pd.concat([trainSet,pd.DataFrame(trainVar_binary)],axis=1)\n",
    "    testSet = pd.concat([testSet,pd.DataFrame(testVar_binary)],axis=1)\n",
    "\n",
    "    # Get missing columns in the test set\n",
    "    missing_categories = set(trainSet) - set(testSet)\n",
    "\n",
    "    # Add the missing columns in test set with default value equal to 0\n",
    "    for c in missing_categories:\n",
    "        testSet[c] = 0\n",
    "\n",
    "    # Get missing columns in the train set\n",
    "    missing_categories = set(testSet) - set(trainSet)\n",
    "\n",
    "    # Add the missing columns in train set with default value equal to 0\n",
    "    for c in missing_categories:\n",
    "        trainSet[c] = 0\n",
    "\n",
    "    # Ensure the order of columns in the test and train sets are the same\n",
    "    trainSet, testSet = trainSet.align(testSet, axis=1)\n",
    "    \n",
    "    # We return the two set\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separons les variables explicatives qualitatives de celles quantitatives\n",
    "df_train_quanti = df_train.drop(['Name','Platform','Genre','Publisher','Developer','Rating'], axis=1)\n",
    "df_test_quanti = df_test.drop(['Platform','Genre','Publisher','Developer','Rating'], axis=1)\n",
    "df_test_quanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Platform.nunique()))\n",
    "\n",
    "df_train_quanti, df_test_quanti = binerizedQualitativeVariable(df_train_quanti, df_test_quanti, df_train.Platform, df_test.Platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Genre.nunique()))\n",
    "\n",
    "df_train_quanti, df_test_quanti = binerizedQualitativeVariable(df_train_quanti, df_test_quanti, df_train.Genre, df_test.Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Publisher.nunique()))\n",
    "\n",
    "#df_train_quanti, df_test_quanti = binerizedQualitativeVariable(df_train_quanti, df_test_quanti, df_train.Publisher, df_test.Publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Developer.nunique()))\n",
    "\n",
    "\"\"\"\n",
    "Bon ici on a un probleme, si on ajoute les colonnes binaires generees par cette variable on ajoute 100mb\n",
    "a notre csv. Ceci rend peu pratique le prototypage, pour l'instant on le laisse tomber. On essayera de ce\n",
    "donner une raison rationnelle de le domper plus tard dans l'analyse. Hypothese, beaucoup de colinearite avec \n",
    "le Publisher.\n",
    "\"\"\"\n",
    "#df_train_quanti, df_test_quanti = binerizedQualitativeVariable(df_train_quanti, df_test_quanti, df_train.Developer, df_test.Developer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories (test) : %d\" %(df_test.Rating.nunique()))\n",
    "\n",
    "df_train_quanti, df_test_quanti = binerizedQualitativeVariable(df_train_quanti, df_test_quanti, df_train.Rating, df_test.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde le nombre de NaN par variables explicatives\n",
    "print(\"Nombre de NaN sur %d observations \\n\" % (len(df_train_quanti)))\n",
    "print(df_train_quanti.isna().sum())\n",
    "\n",
    "# On garde seulement les observations ou nous avons toutes les donnees (a ameliorer plus tard)\n",
    "df_train_quanti = df_train_quanti.dropna()\n",
    "\n",
    "# On calcule le nombre d'observations restantes\n",
    "print(\"\\nApres clean-up, nombre d'observation : %d\" % (len(df_train_quanti)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enleve les colonnes qui ne comportent que des zeros\n",
    "cols_only0 = (df_train_quanti != 0).any(axis=0)\n",
    "df_train_quanti = df_train_quanti.loc[:,cols_only0]\n",
    "df_test_quanti = df_test_quanti.loc[:,cols_only0]\n",
    "\n",
    "# On enleve toutes les colonnes qui sont en double\n",
    "duplicates = df_train_quanti.T.duplicated()\n",
    "duplicates = ~duplicates\n",
    "df_train_quanti = df_train_quanti.T[duplicates].T\n",
    "df_test_quanti = df_test_quanti.T[duplicates].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sauvegarde nos deux nouveaux jeux de donnees entierement quantitatif\n",
    "#df_train_quanti.to_csv(\"train_quanti.csv\")\n",
    "#df_test_quanti.to_csv(\"test_quanti.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_quanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(y,x):\n",
    "    \n",
    "    # Number of Explicative Variables\n",
    "    k = 0\n",
    "    try:\n",
    "        k = x.shape[1]\n",
    "    except IndexError:\n",
    "        k = 1\n",
    "        \n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(np.dot(x.T,x))\n",
    "    \n",
    "    B = np.dot(np.dot(C,x.T),y)\n",
    "    \n",
    "    return B, np.dot(x,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_adj(Y,W,p):\n",
    "\n",
    "    SS_tot = 0.0\n",
    "    SS_reg = 0.0\n",
    "    SS_res = 0.0    \n",
    "    \n",
    "    y_S = np.sum(Y)/len(Y)\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        SS_tot += (Y[i] - y_S)**2\n",
    "        SS_reg += (W[i] - y_S)**2\n",
    "        SS_res += (Y[i] - W[i])**2\n",
    "        \n",
    "    \n",
    "    n = len(Y)\n",
    "    \n",
    "    Radj = 1 - ((SS_res)/float(n-p))/((SS_tot)/(n-1))\n",
    "\n",
    "    return Radj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit notre variable d'interet\n",
    "Y = np.array(df_train_quanti.NA_Sales)\n",
    "\n",
    "# On definit notre vecteur de variables explicatives\n",
    "X = np.array(df_train_quanti.drop(['NA_Sales','Global_Sales'], axis=1))\n",
    "nbrOfVar = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'assure que nos matrices soient toutes dans la bonne position\n",
    "print(\"Y Shape : \",Y.shape)\n",
    "print(\"X Shape : \",X.shape)\n",
    "print(\"Nbr de Variables : \",nbrOfVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On effectue notre regression lineaire\n",
    "try:\n",
    "    b, data = linear_regression(Y,X)\n",
    "    RMSE(Y,data)\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"NUL, hahaha determinant = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We standardize our data because PCA is sensitive to scaling\n",
    "X_std = StandardScaler().fit_transform(X) # (mean=0 and variance=1)\n",
    "\n",
    "# The Mean Matrix\n",
    "u = np.mean(X_std, axis=0)\n",
    "\n",
    "# The covariance matrix\n",
    "E = np.dot((X_std).T,(X_std))/(X_std.shape[0]-1)\n",
    "#print('Covariance matrix \\n%s' % E)\n",
    "\n",
    "# Eigenvalues and Eigenvectors\n",
    "eig_val, eig_vec = np.linalg.eig(E) #vector already normalized\n",
    "eig_val = eig_val.real\n",
    "eig_val_fraction = eig_val/np.sum(eig_val)\n",
    "eig_val_fraction = -np.sort(-eig_val_fraction)\n",
    "\n",
    "\n",
    "#print('Eigenvectors \\n%s' %eig_vec)\n",
    "#print('\\nEigenvalues \\n%s' %eig_val)\n",
    "sum = 0.0\n",
    "for i in range(len(eig_val)):\n",
    "    if(eig_val_fraction[i] >= 0.002):\n",
    "        sum += eig_val_fraction[i]\n",
    "        print(\"Eig Val %d = %.4f, sum : %.4f\" % (i,eig_val_fraction[i],sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
