{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "L'algorithme R2_prev implemente une validation croise sur l'ensemble du jeu de donnees fournis\n",
    "\n",
    "Arguments:\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    X : Nos variables explicatives\n",
    "    \n",
    "\n",
    "\n",
    "Retourne:\n",
    "\n",
    "    R2_prev : Une mesure bornee entre [-inf, 1] qui represente le pouvoir predictif de nos estimations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def R2_prev(Y,W,X):\n",
    "    \n",
    "    # On multiplie X par soi meme\n",
    "    X2 = np.dot(X.T,X)  \n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(X2)\n",
    "    \n",
    "    # Hat Matrix (X*B = H*Y)\n",
    "    H = np.dot(np.dot(X,C),X.T)\n",
    "    \n",
    "    # We are only interested in the (i,i) values\n",
    "    H = np.diagonal(H)\n",
    "    \n",
    "    # Mean of Y\n",
    "    y_S = np.sum(Y)/float(len(Y))\n",
    "    \n",
    "    num = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        num += ((Y[i] - W[i])/float(1 - H[i]))**2\n",
    "\n",
    "    denom = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        denom += (Y[i] - y_S)**2\n",
    "    \n",
    "    R2_prev = (1 - num/denom)\n",
    "    \n",
    "    return R2_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Selon le document MTH3302_CriteresProjet.pdf nous sommes evalues par notre root mean squared error (RMSE).\n",
    "On trouve ici son implementation.\n",
    "\n",
    "Arguments :\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    \n",
    "    \n",
    "Retourne:\n",
    "    rmse : L'erreur moyenne de nos predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RMSE(Y,W):\n",
    "\n",
    "    n = len(Y)\n",
    "\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += (Y[i] - W[i])**2\n",
    "        \n",
    "    rmse = total/float(n)\n",
    "        \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous avons une fonction qui la tranforme en table binaire \n",
    "avec un one bit encoder. \n",
    "\n",
    "    Disons que la variable explicative peut prendre 4 valeurs {Bleu, Vert, Jaune, Rouge},\n",
    "        \n",
    "          ID        X1\n",
    "        ----------------\n",
    "          1        Bleu\n",
    "          2        Bleu\n",
    "          3        Vert\n",
    "          4        Jaune\n",
    "          5        Vert\n",
    "          6        Rouge          \n",
    "         ...\n",
    "    \n",
    "    Suite a un encodage en 1 bit notre variable explicative X1 devient,\n",
    "    \n",
    "          ID        Bleu        Vert        Jaune        Rouge\n",
    "        -------------------------------------------------------\n",
    "          1          1           0            0            0\n",
    "          2          1           0            0            0\n",
    "          3          0           1            0            0\n",
    "          4          0           0            1            0\n",
    "          5          0           1            0            0\n",
    "          6          0           0            0            1\n",
    "                                ...\n",
    "                                \n",
    "\n",
    "Nous nous basons sur la fonction get_dummies() de la librairie Panda pour faire ceci.\n",
    "\n",
    "\n",
    "Arguments,\n",
    "\n",
    "    trainSet : le jeu de donnees de training\n",
    "    testSet : le jeu de donnees de test\n",
    "    varName : la variable qualitative que nous souhaitons transformer en tableau binaire\n",
    "    \n",
    "    \n",
    "Retourne, \n",
    "    trainSet_new : le jeu de donnees de training ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "    testSet_new : le jeu de donnees de test ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def qualiToBinary(trainSet, testSet, varName):\n",
    "    \n",
    "    # Genere la table binaire de la variable qualitative\n",
    "    trainVar_binary = pd.get_dummies(trainSet[varName],prefix=varName)\n",
    "    testVar_binary = pd.get_dummies(testSet[varName],prefix=varName)\n",
    "    \n",
    "    # On convertit nos tableaux binaires en Dataframe\n",
    "    trainVar_binary = pd.DataFrame(trainVar_binary)\n",
    "    testVar_binary = pd.DataFrame(testVar_binary)\n",
    "    \n",
    "    # On enleve la variable qualitative de nos jeux de donnees\n",
    "    trainSet_new = trainSet.drop([varName], axis=1)\n",
    "    testSet_new = testSet.drop([varName], axis=1)   \n",
    "\n",
    "    # On ajoute les nouvelles colonnes a nos jeux de donnees\n",
    "    trainSet_new = pd.concat([trainSet_new,trainVar_binary],axis=1)\n",
    "    testSet_new = pd.concat([testSet_new,testVar_binary],axis=1)\n",
    "    \n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees test\n",
    "    missing_categories = set(trainSet_new) - set(testSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        testSet_new[c] = 0\n",
    "\n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees training\n",
    "    missing_categories = set(testSet_new) - set(trainSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        trainSet_new[c] = 0\n",
    "\n",
    "\n",
    "    # On aligne nos jeux de donnees pour que les memes colonnes soient aux memes endroits\n",
    "    trainSet_new, testSet_new = trainSet_new.align(testSet_new, axis=1)\n",
    "    \n",
    "    # On retourne les jeux de donnees\n",
    "    return trainSet_new, testSet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(Y,X,varExplained):\n",
    "        \n",
    "    # On transforme X en une matrice de moyenne = 0 et variance = 1\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    nbrOfVar = X.shape[1]\n",
    "\n",
    "    # On calcule la matrice de covariance\n",
    "    E = np.dot(X_std.T,X_std)/(nbrOfVar-1)\n",
    "\n",
    "    # On calcule nos Valeurs et Vecteurs propres\n",
    "    eig_val, eig_vec = np.linalg.eig(E)\n",
    "    eig_val = eig_val.real\n",
    "    eig_vec = eig_vec.real\n",
    "    eig_vec = eig_vec.T # pour les ordonner par range\n",
    "\n",
    "    # On calcule la contribution de chaque valeur propre a la variance total\n",
    "    eig_val_contribution = eig_val/np.sum(eig_val)\n",
    "\n",
    "    # On cree une liste d'index de 0 au nombre de valeurs propres\n",
    "    rangeIndex = np.array(range(len(eig_val_contribution)))\n",
    "\n",
    "    # On cree un tableau indexe de nos valeurs propres et leur contribution a la variance\n",
    "    eig_val_table = np.array(([rangeIndex,eig_val,eig_val_contribution])).T\n",
    "\n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    eig_val_table_ordered = eig_val_table[(-eig_val_table[:,2]).argsort()]\n",
    "    \n",
    "    # On rejoint la quantite de variance souhaitee\n",
    "    varCumul = 0.0\n",
    "    varIndex = 0\n",
    "    for val in eig_val_table_ordered:\n",
    "        varIndex += 1\n",
    "        varCumul += val[2]\n",
    "        if(varCumul >= varExplained):\n",
    "            break\n",
    "    \n",
    "    print(\"Nbr of Var = %d\" % varIndex)\n",
    "    \n",
    "    # On recupere les index des valeurs propres que nous garderont\n",
    "    indexKept = eig_val_table_ordered[:,0][:varIndex]\n",
    "\n",
    "    # Our reduced regressor\n",
    "    K_vect = eig_vec[indexKept.astype(int),:].T\n",
    "\n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "\n",
    "    # Our Regression Coefficiants\n",
    "    B_partial = np.dot(np.linalg.inv(np.dot(Z.T,Z)),Z.T)\n",
    "    B = np.dot(B_partial,Y)\n",
    "\n",
    "    # We calculate the intercept\n",
    "    uY = np.mean(Y)\n",
    "\n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "\n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "    \n",
    "    return Y_new, B, K_vect, uY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_trained(X,B,K_vect,uY):\n",
    "    \n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "    \n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "    \n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "\n",
    "    return Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies\n",
    "import numpy as np # calcul matriciel\n",
    "import pandas as pd # structure des donnees\n",
    "import matplotlib.pyplot as plt # graphiques\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Chemin vers les jeux de donnees en format csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# On importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)\n",
    "\n",
    "# On enleve la colonne Name qui ne sert pas a l'analyse\n",
    "df_train = df_train.drop(['Name'],axis=1)\n",
    "\n",
    "\n",
    "# --- Variables Explicatives ---\n",
    "\n",
    "#    Name : Nom du jeu\n",
    "#    Platform : Console sur laquelle le jeu fonctionne\n",
    "#    Year_of_Release : Année de sortie du jeu\n",
    "#    Genre\n",
    "#    Publisher\n",
    "#    JP_Sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "#    Other_Sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "#    Critic_Score : Score donné par Metacritic\n",
    "#    Critic_Count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "#    User_Score : Score donné par les usagers de Metacritic\n",
    "#    User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "#    Developer : Compagnie créatrice du jeu\n",
    "#    Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "\n",
    "# --- Variables d'Interet ---\n",
    "\n",
    "#    NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "#    Global_Sales : Nombre de ventes total du jeu en millions d’unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories Platform (train) : 30\n",
      "Nbr. of categories Platform (test) : 27 \n",
      "\n",
      "Nbr. of categories Genre (train) : 12\n",
      "Nbr. of categories Genre (test) : 12 \n",
      "\n",
      "Nbr. of categories Publisher (train) : 552\n",
      "Nbr. of categories Publisher (test) : 280 \n",
      "\n",
      "Nbr. of categories Developer (train) : 1593\n",
      "Nbr. of categories Developer (test) : 677 \n",
      "\n",
      "Nbr. of categories Rating (train) : 8\n",
      "Nbr. of categories Rating (test) : 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on transforme nos variables qualitatives en tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories Platform (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories Platform (test) : %d \\n\" %(df_test.Platform.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Platform') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories Genre (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories Genre (test) : %d \\n\" %(df_test.Genre.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Genre') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories Publisher (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories Publisher (test) : %d \\n\" %(df_test.Publisher.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Publisher') # On binairise\n",
    "#df_train = df_train.drop(['Publisher'], axis=1)\n",
    "#df_test = df_test.drop(['Publisher'], axis=1)\n",
    "\n",
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories Developer (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories Developer (test) : %d \\n\" %(df_test.Developer.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Developer') # On binairise\n",
    "#df_train = df_train.drop(['Developer'], axis=1)\n",
    "#df_test = df_test.drop(['Developer'], axis=1)\n",
    "\n",
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories Rating (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories Rating (test) : %d \\n\" %(df_test.Rating.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Rating') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(df_train.mean())\n",
    "df_test = df_test.fillna(df_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIci on ajoute de nouvelles colonnes qui sont des combinaisons non-lineaires \\n\\ndes autres colonnes ou de toute nouvelles informations.\\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on ajoute de nouvelles colonnes qui sont des combinaisons non-lineaires \n",
    "\n",
    "des autres colonnes ou de toute nouvelles informations.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une matrice de nos variables\n",
    "X_train = df_train.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "X_test = df_test.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "\n",
    "# On isole nos variables d'interet\n",
    "Y1 = df_train.Global_Sales.values\n",
    "Y2 = df_train.NA_Sales.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14094, 2332)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c27d6598d5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE = %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA_trained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-1e6db9c0d2d1>\u001b[0m in \u001b[0;36mPCA\u001b[0;34m(Y, X, varExplained)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Our Regression Coefficiants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mB_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_partial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "Y_new, B, K_vect, uY = PCA(Y1,X_train,0.7)\n",
    "print(\"RMSE = %.4f\" % RMSE(Y1,Y_new))\n",
    "\n",
    "Y1_test = PCA_trained(X_test,B, K_vect, uY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr of Var = 1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean-romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.3594\n"
     ]
    }
   ],
   "source": [
    "Y_new, B, K_vect, uY = PCA(Y2,X_train,0.7)\n",
    "print(\"RMSE = %.4f\" % RMSE(Y2,Y_new))\n",
    "\n",
    "Y2_test = PCA_trained(X_test,B, K_vect, uY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Processing du jeu de donnees test\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On vient prendre le dataframe comme canva\n",
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "# On assigne nos predictions aux colonnes\n",
    "df_test_estimated['Global_Sales'] = Y1_test\n",
    "df_test_estimated['NA_Sales'] = Y2_test\n",
    "\n",
    "# On sauvegarde nos predictions\n",
    "df_test_estimated.to_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
