{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(Y,X,varExplained):\n",
    "        \n",
    "    # On transforme X en une matrice de moyenne = 0 et variance = 1\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    nbrOfVar = X.shape[1]\n",
    "\n",
    "    # On calcule la matrice de covariance\n",
    "    E = np.dot(X_std.T,X_std)/(nbrOfVar-1)\n",
    "\n",
    "    # On calcule nos Valeurs et Vecteurs propres\n",
    "    eig_val, eig_vec = np.linalg.eig(E)\n",
    "    eig_val = eig_val.real\n",
    "    eig_vec = eig_vec.T # pour les ordonner par range\n",
    "\n",
    "    # On calcule la contribution de chaque valeur propre a la variance total\n",
    "    eig_val_contribution = eig_val/np.sum(eig_val)\n",
    "\n",
    "    # On cree une liste d'index de 0 au nombre de valeurs propres\n",
    "    rangeIndex = np.array(range(len(eig_val_contribution)))\n",
    "\n",
    "    # On cree un tableau indexe de nos valeurs propres et leur contribution a la variance\n",
    "    eig_val_table = np.array(([rangeIndex,eig_val,eig_val_contribution])).T\n",
    "\n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    eig_val_table_ordered = eig_val_table[(-eig_val_table[:,2]).argsort()]\n",
    "    \n",
    "    # On rejoint la quantite de variance souhaitee\n",
    "    varCumul = 0.0\n",
    "    varIndex = 0\n",
    "    for val in eig_val_table_ordered:\n",
    "        varIndex += 1\n",
    "        varCumul += val[2]\n",
    "        if(varCumul >= varExplained):\n",
    "            break\n",
    "    \n",
    "    # On recupere les index des valeurs propres que nous garderont\n",
    "    indexKept = eig_val_table_ordered[:,0][:varIndex]\n",
    "\n",
    "    # Our reduced regressor\n",
    "    K_vect = eig_vec[indexKept.astype(int),:].T\n",
    "\n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "\n",
    "    # Our Regression Coefficiants\n",
    "    B_partial = np.dot(np.linalg.inv(np.dot(Z.T,Z)),Z.T)\n",
    "    B = np.dot(B_partial,Y)\n",
    "\n",
    "    # We calculate the intercept\n",
    "    uY = np.mean(Y)\n",
    "\n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "\n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "    \n",
    "    return Y_new, B, K_vect, uY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_trained(X,B,K_vect,uY):\n",
    "    \n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "    \n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "    \n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "\n",
    "    return Y_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateCol(trainSet,testSet,colName,varExplained):\n",
    "    \n",
    "    # On definit notre variable d'interet\n",
    "    Y = np.array(trainSet[colName])\n",
    "\n",
    "    # On definit notre vecteur de variables explicatives\n",
    "    X = np.array(trainSet.drop([colName], axis=1))\n",
    "\n",
    "    # We train our model\n",
    "    [Y_new, B, K_vect, uY] = PCA(Y,X,varExplained)\n",
    "    \n",
    "    X_test = np.array(testSet.drop([colName], axis=1))    \n",
    "    Y_test = PCA_trained(X_test,B,K_vect,uY)\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-38be0e555686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_estimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNA_Sales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobal_Sales\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "\n",
    "df_test_estimated['NA_Sales'] = estimateCol(df_train,df_test,'NA_Sales',0.999)\n",
    "df_test_estimated['Global_Sales'] = estimateCol(df_train,df_test,'Global_Sales',0.999)\n",
    "\n",
    "# On definit notre vecteur de variables explicatives\n",
    "X1 = np.array(trainSet.drop(['Global_Sales'], axis=1))\n",
    "X2 = np.array(trainSet.drop(['NA_Sales'], axis=1))\n",
    "\n",
    "Y1 = df_test_estimated.Global_Sales.values\n",
    "Y2 = df_test_estimated.NA_Sales.values\n",
    "\n",
    "print(\"Global R2_prev : %.3f\" % (R2_prev(Y1,np.dot(X1,B1),X)))\n",
    "print(\"NA R2_prev : %.3f\" % (R2_prev(Y2,np.dot(X2,B2),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
