{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(Y,X,varExplained):\n",
    "        \n",
    "    # On transforme X en une matrice de moyenne = 0 et variance = 1\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    nbrOfVar = X.shape[1]\n",
    "\n",
    "    # On calcule la matrice de covariance\n",
    "    E = np.dot(X_std.T,X_std)/(nbrOfVar-1)\n",
    "\n",
    "    # On calcule nos Valeurs et Vecteurs propres\n",
    "    eig_val, eig_vec = np.linalg.eig(E)\n",
    "    eig_val = eig_val.real\n",
    "    eig_vec = eig_vec.T # pour les ordonner par range\n",
    "\n",
    "    # On calcule la contribution de chaque valeur propre a la variance total\n",
    "    eig_val_contribution = eig_val/np.sum(eig_val)\n",
    "\n",
    "    # On cree une liste d'index de 0 au nombre de valeurs propres\n",
    "    rangeIndex = np.array(range(len(eig_val_contribution)))\n",
    "\n",
    "    # On cree un tableau indexe de nos valeurs propres et leur contribution a la variance\n",
    "    eig_val_table = np.array(([rangeIndex,eig_val,eig_val_contribution])).T\n",
    "\n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    eig_val_table_ordered = eig_val_table[(-eig_val_table[:,2]).argsort()]\n",
    "    \n",
    "    # On rejoint la quantite de variance souhaitee\n",
    "    varCumul = 0.0\n",
    "    varIndex = 0\n",
    "    for val in eig_val_table_ordered:\n",
    "        varIndex += 1\n",
    "        varCumul += val[2]\n",
    "        if(varCumul >= varExplained):\n",
    "            break\n",
    "    \n",
    "    # On recupere les index des valeurs propres que nous garderont\n",
    "    indexKept = eig_val_table_ordered[:,0][:varIndex]\n",
    "\n",
    "    # Our reduced regressor\n",
    "    K_vect = eig_vec[indexKept.astype(int),:].T\n",
    "\n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "\n",
    "    # Our Regression Coefficiants\n",
    "    B_partial = np.dot(np.linalg.inv(np.dot(Z.T,Z)),Z.T)\n",
    "    B = np.dot(B_partial,Y)\n",
    "\n",
    "    # We calculate the intercept\n",
    "    uY = np.mean(Y)\n",
    "\n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "\n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "    \n",
    "    return Y_new, B, K_vect, uY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_trained(X,B,K_vect,uY):\n",
    "    \n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "    \n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "    \n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "\n",
    "    return Y_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateCol(trainSet,testSet,colName,varExplained):\n",
    "    \n",
    "    # On definit notre variable d'interet\n",
    "    Y = np.array(trainSet[colName])\n",
    "\n",
    "    # On definit notre vecteur de variables explicatives\n",
    "    X = np.array(trainSet.drop([colName], axis=1))\n",
    "\n",
    "    # We train our model\n",
    "    [Y_new, B, K_vect, uY] = PCA(Y,X,varExplained)\n",
    "    \n",
    "    X_test = np.array(testSet.drop([colName], axis=1))    \n",
    "    Y_test = PCA_trained(X_test,B,K_vect,uY)\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-38be0e555686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_estimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNA_Sales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobal_Sales\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "\n",
    "df_test_estimated['NA_Sales'] = estimateCol(df_train,df_test,'NA_Sales',0.999)\n",
    "df_test_estimated['Global_Sales'] = estimateCol(df_train,df_test,'Global_Sales',0.999)\n",
    "\n",
    "# On definit notre vecteur de variables explicatives\n",
    "X1 = np.array(trainSet.drop(['Global_Sales'], axis=1))\n",
    "X2 = np.array(trainSet.drop(['NA_Sales'], axis=1))\n",
    "\n",
    "Y1 = df_test_estimated.Global_Sales.values\n",
    "Y2 = df_test_estimated.NA_Sales.values\n",
    "\n",
    "print(\"Global R2_prev : %.3f\" % (R2_prev(Y1,np.dot(X1,B1),X)))\n",
    "print(\"NA R2_prev : %.3f\" % (R2_prev(Y2,np.dot(X2,B2),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Fonction qui affiche la valeur moyenne de la variable d'interet en fonction des \n",
    "valeurs d'une variable explicative qualitative.\n",
    "\n",
    "Arguments:\n",
    "    dataset : Le jeu de donnees sur lequel nous appliquons la fonction\n",
    "    Y : la variable d'interet\n",
    "    colName : Le nom de la variable qualitative que nous souhaitons etudier\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clusterVar(dataset,Y,colsName,minNbr=0):\n",
    "    \n",
    "    # On selectionne seulement les colonnes qui debute par 'colsName'\n",
    "    reducedSet = dataset.loc[:, dataset.columns.str.startswith(colsName)]\n",
    "    \n",
    "    # On calcule le nombre de colonne\n",
    "    nbrOfCols = len(reducedSet.T)\n",
    "    \n",
    "    # On cree une liste d'index de 0 au nombre de colonne\n",
    "    rangeIndex = np.array(range(nbrOfCols))\n",
    "    \n",
    "    sumWithX = np.zeros(nbrOfCols)\n",
    "    valueCount = np.zeros(nbrOfCols)\n",
    "    names = np.array(['' for _ in range(nbrOfCols)], dtype=object)\n",
    "    index = 0\n",
    "    for col in reducedSet:\n",
    "        withX = reducedSet[col]*Y\n",
    "        sumWithX[index] = np.sum(withX)/(withX.astype(bool).sum(axis=0))\n",
    "        if(np.isnan(sumWithX[index])):\n",
    "            sumWithX[index] = 0\n",
    "        valueCount[index] = reducedSet[col].astype(bool).sum(axis=0)\n",
    "        names[index] += col\n",
    "        index += 1\n",
    "    \n",
    "    # On cree un tableau indexe de nos categories, leur quantite et leur valeur moyenne de la variable d'interet\n",
    "    aveY_table = np.array(([rangeIndex,sumWithX,valueCount,names])).T\n",
    "    \n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    aveY_table_ordered = aveY_table[(-aveY_table[:,1]).argsort()]\n",
    "    \n",
    "    print('Index \\t Moy \\t Nbr \\t Name')    \n",
    "    print('------------------------------------------')\n",
    "    for i in range(nbrOfCols):\n",
    "        if(aveY_table_ordered[i][2] > minNbr):\n",
    "            print('%d. \\t %.3f \\t %d \\t %s ' % (aveY_table_ordered[i][0],aveY_table_ordered[i][1],aveY_table_ordered[i][2],aveY_table_ordered[i][3]))\n",
    "            \n",
    "     \n",
    "    newIndex = 0\n",
    "    print('\\n\\n\\n')    \n",
    "    for i in range(nbrOfCols):\n",
    "        if(aveY_table_ordered[i][2] > minNbr):\n",
    "            newIndex += 1\n",
    "            print(\"X12_%d = testSet['%s'].values\" % (newIndex,aveY_table_ordered[i][3]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Regression lineaire par methode des moindres carres \n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : Matrice contenant nos variables explicatives (dimension : n x (p+1))\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative\n",
    "    \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = Matrices de nos coefficiants de regression (dimension (p+1) x 1)\n",
    "\n",
    "    Pour estimer la valeur de y_new avec de nouvelles observations (i.e. x_new) on a,\n",
    "        y_new = np.dot(x_new,B)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def linear_regression(y,x):\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance\n",
    "    C = np.linalg.inv(np.dot(x.T,x))\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(np.dot(C,x.T),y)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
