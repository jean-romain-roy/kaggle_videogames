{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(Y,X,varExplained):\n",
    "        \n",
    "    # On transforme X en une matrice de moyenne = 0 et variance = 1\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    nbrOfVar = X.shape[1]\n",
    "\n",
    "    # On calcule la matrice de covariance\n",
    "    E = np.dot(X_std.T,X_std)/(nbrOfVar-1)\n",
    "\n",
    "    # On calcule nos Valeurs et Vecteurs propres\n",
    "    eig_val, eig_vec = np.linalg.eig(E)\n",
    "    eig_val = eig_val.real\n",
    "    eig_vec = eig_vec.T # pour les ordonner par range\n",
    "\n",
    "    # On calcule la contribution de chaque valeur propre a la variance total\n",
    "    eig_val_contribution = eig_val/np.sum(eig_val)\n",
    "\n",
    "    # On cree une liste d'index de 0 au nombre de valeurs propres\n",
    "    rangeIndex = np.array(range(len(eig_val_contribution)))\n",
    "\n",
    "    # On cree un tableau indexe de nos valeurs propres et leur contribution a la variance\n",
    "    eig_val_table = np.array(([rangeIndex,eig_val,eig_val_contribution])).T\n",
    "\n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    eig_val_table_ordered = eig_val_table[(-eig_val_table[:,2]).argsort()]\n",
    "    \n",
    "    # On rejoint la quantite de variance souhaitee\n",
    "    varCumul = 0.0\n",
    "    varIndex = 0\n",
    "    for val in eig_val_table_ordered:\n",
    "        varIndex += 1\n",
    "        varCumul += val[2]\n",
    "        if(varCumul >= varExplained):\n",
    "            break\n",
    "    \n",
    "    # On recupere les index des valeurs propres que nous garderont\n",
    "    indexKept = eig_val_table_ordered[:,0][:varIndex]\n",
    "\n",
    "    # Our reduced regressor\n",
    "    K_vect = eig_vec[indexKept.astype(int),:].T\n",
    "\n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "\n",
    "    # Our Regression Coefficiants\n",
    "    B_partial = np.dot(np.linalg.inv(np.dot(Z.T,Z)),Z.T)\n",
    "    B = np.dot(B_partial,Y)\n",
    "\n",
    "    # We calculate the intercept\n",
    "    uY = np.mean(Y)\n",
    "\n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "\n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "    \n",
    "    return Y_new, B, K_vect, uY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_trained(X,B,K_vect,uY):\n",
    "    \n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Our principal components\n",
    "    Z = np.dot(X_std,K_vect)\n",
    "    \n",
    "    # We add the intercept\n",
    "    Y_new = np.dot(Z,B) + uY\n",
    "    \n",
    "    # Clip to min 0\n",
    "    Y_new = Y_new.clip(min=0)\n",
    "\n",
    "    return Y_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateCol(trainSet,testSet,colName,varExplained):\n",
    "    \n",
    "    # On definit notre variable d'interet\n",
    "    Y = np.array(trainSet[colName])\n",
    "\n",
    "    # On definit notre vecteur de variables explicatives\n",
    "    X = np.array(trainSet.drop([colName], axis=1))\n",
    "\n",
    "    # We train our model\n",
    "    [Y_new, B, K_vect, uY] = PCA(Y,X,varExplained)\n",
    "    \n",
    "    X_test = np.array(testSet.drop([colName], axis=1))    \n",
    "    Y_test = PCA_trained(X_test,B,K_vect,uY)\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-38be0e555686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_estimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNA_Sales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobal_Sales\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NA_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_test_estimated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimateCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Global_Sales'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "\n",
    "df_test_estimated['NA_Sales'] = estimateCol(df_train,df_test,'NA_Sales',0.999)\n",
    "df_test_estimated['Global_Sales'] = estimateCol(df_train,df_test,'Global_Sales',0.999)\n",
    "\n",
    "# On definit notre vecteur de variables explicatives\n",
    "X1 = np.array(trainSet.drop(['Global_Sales'], axis=1))\n",
    "X2 = np.array(trainSet.drop(['NA_Sales'], axis=1))\n",
    "\n",
    "Y1 = df_test_estimated.Global_Sales.values\n",
    "Y2 = df_test_estimated.NA_Sales.values\n",
    "\n",
    "print(\"Global R2_prev : %.3f\" % (R2_prev(Y1,np.dot(X1,B1),X)))\n",
    "print(\"NA R2_prev : %.3f\" % (R2_prev(Y2,np.dot(X2,B2),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Fonction qui affiche la valeur moyenne de la variable d'interet en fonction des \n",
    "valeurs d'une variable explicative qualitative.\n",
    "\n",
    "Arguments:\n",
    "    dataset : Le jeu de donnees sur lequel nous appliquons la fonction\n",
    "    Y : la variable d'interet\n",
    "    colName : Le nom de la variable qualitative que nous souhaitons etudier\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def clusterVar(dataset,Y,colsName,minNbr=0):\n",
    "    \n",
    "    # On selectionne seulement les colonnes qui debute par 'colsName'\n",
    "    reducedSet = dataset.loc[:, dataset.columns.str.startswith(colsName)]\n",
    "    \n",
    "    # On calcule le nombre de colonne\n",
    "    nbrOfCols = len(reducedSet.T)\n",
    "    \n",
    "    # On cree une liste d'index de 0 au nombre de colonne\n",
    "    rangeIndex = np.array(range(nbrOfCols))\n",
    "    \n",
    "    sumWithX = np.zeros(nbrOfCols)\n",
    "    valueCount = np.zeros(nbrOfCols)\n",
    "    names = np.array(['' for _ in range(nbrOfCols)], dtype=object)\n",
    "    index = 0\n",
    "    for col in reducedSet:\n",
    "        withX = reducedSet[col]*Y\n",
    "        sumWithX[index] = np.sum(withX)/(withX.astype(bool).sum(axis=0))\n",
    "        if(np.isnan(sumWithX[index])):\n",
    "            sumWithX[index] = 0\n",
    "        valueCount[index] = reducedSet[col].astype(bool).sum(axis=0)\n",
    "        names[index] += col\n",
    "        index += 1\n",
    "    \n",
    "    # On cree un tableau indexe de nos categories, leur quantite et leur valeur moyenne de la variable d'interet\n",
    "    aveY_table = np.array(([rangeIndex,sumWithX,valueCount,names])).T\n",
    "    \n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    aveY_table_ordered = aveY_table[(-aveY_table[:,1]).argsort()]\n",
    "    \n",
    "    print('Index \\t Moy \\t Nbr \\t Name')    \n",
    "    print('------------------------------------------')\n",
    "    for i in range(nbrOfCols):\n",
    "        if(aveY_table_ordered[i][2] > minNbr):\n",
    "            print('%d. \\t %.3f \\t %d \\t %s ' % (aveY_table_ordered[i][0],aveY_table_ordered[i][1],aveY_table_ordered[i][2],aveY_table_ordered[i][3]))\n",
    "            \n",
    "     \n",
    "    newIndex = 0\n",
    "    print('\\n\\n\\n')    \n",
    "    for i in range(nbrOfCols):\n",
    "        if(aveY_table_ordered[i][2] > minNbr):\n",
    "            newIndex += 1\n",
    "            print(\"X12_%d = testSet['%s'].values\" % (newIndex,aveY_table_ordered[i][3]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Regression lineaire par methode des moindres carres \n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : Matrice contenant nos variables explicatives (dimension : n x (p+1))\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative\n",
    "    \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = Matrices de nos coefficiants de regression (dimension (p+1) x 1)\n",
    "\n",
    "    Pour estimer la valeur de y_new avec de nouvelles observations (i.e. x_new) on a,\n",
    "        y_new = np.dot(x_new,B)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def linear_regression(y,x):\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance\n",
    "    C = np.linalg.inv(np.dot(x.T,x))\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(np.dot(C,x.T),y)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on a une fonction pour nous aider a visualiser les coefficiants de regression.\n",
    "\n",
    "Puisque notre matrice de variables explicatives est normalisee, un haut coefficiant b_i indique \n",
    "une importance de la variable X_i\n",
    "\n",
    "Par contre nous ne testons pas ici des relations du type : log(X_i), X_i^2, X_(i+1)*X_i, etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cofficientTrier(dataset,Y,l,coeffThreshold):\n",
    "    \n",
    "    # On cree la matrice de nos variables explicatives\n",
    "    X = dataset.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "    \n",
    "    # On enleve les colonnes qui comportent que des 0\n",
    "    X = X.loc[:, (X != 0).any(axis=0)]\n",
    "    \n",
    "    # Transformation, moy = 0, var = 1\n",
    "    X_std = scaler(X.values)\n",
    "    \n",
    "    # On effectue la regression\n",
    "    B = ridge_regression(Y,X_std,l)\n",
    "    \n",
    "    # On calcule la somme des B\n",
    "    sumB = np.sum(np.abs(B))    \n",
    "    \n",
    "    # On calcule le nombre de colonne\n",
    "    nbrOfCols = len(X.T)\n",
    "    \n",
    "    \n",
    "    indexes = np.zeros(nbrOfCols)\n",
    "    coeffs = np.zeros(nbrOfCols)\n",
    "    coeffsFrac = np.zeros(nbrOfCols)\n",
    "    sumBFrac = 0\n",
    "    names = np.array(['' for _ in range(nbrOfCols)], dtype=object)\n",
    "    index = 0\n",
    "    index2 = 0\n",
    "    for col in X:\n",
    "        if((B[index]/sumB) >= coeffThreshold):\n",
    "            names[index2] += col\n",
    "            indexes[index2] = index\n",
    "            coeffs[index2] = B[index]\n",
    "            coeffsFrac[index2] = np.abs(B[index])/sumB\n",
    "            sumBFrac += coeffsFrac[index2]\n",
    "            index2 += 1\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    # On cree un tableau indexe de nos categories, leur quantite et leur valeur moyenne de la variable d'interet\n",
    "    table = np.array(([indexes,coeffsFrac,names])).T\n",
    "    \n",
    "    # On enleve les ranges de 0\n",
    "    table = table[~np.all(table == 0, axis=1)]\n",
    "    \n",
    "    # On ordonne en ordre decroissant de contribution le tableau\n",
    "    table_ordered = table[(-table[:,1]).argsort()] \n",
    "    \n",
    "    print(\"Fraction of B displayed = %.3f %%\" % sumBFrac)\n",
    "    print('Index \\t B_i %% \\t Name \\t (l = %.2f  -  minB = %.3f %%)' % (l,coeffThreshold))    \n",
    "    print('------------------------------------------')\n",
    "    for i in range(index2):\n",
    "        sumBFrac += table_ordered[i][1]\n",
    "        print('%d. \\t %.3f \\t %s ' % (table_ordered[i][0],table_ordered[i][1],table_ordered[i][2]))\n",
    "    \n",
    "    \"\"\" SI ON VEUT COPIER COLLER LE NOM DES VAR ON ENLEVE COMMENTAIRE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    for i in range(index2):\n",
    "        print(\"X%d = dataset['%s'].values\" % (i,table_ordered[i][2]))\n",
    "\n",
    "    print('\\n')\n",
    "        \n",
    "    for i in range(index2):\n",
    "        print(\"X%d,\" % i)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_Global(dataset):\n",
    "    \n",
    "    # On dresse la liste des variables explicatives qu'on souhaite inclure\n",
    "    # Variables Quantitatives\n",
    "    \n",
    "    \n",
    "    # Platform\n",
    "    X8_4 = dataset.Platform_SNES.values\n",
    "    X8_5 = dataset.Platform_X360.values\n",
    "    X8_7 = dataset.Platform_2600.values\n",
    "    X8_8 = dataset.Platform_Wii.values\n",
    "    X8_10 = dataset.Platform_N64.values\n",
    "    X8_11 = dataset.Platform_XOne.values\n",
    "    X8_17 = dataset.Platform_GBA.values\n",
    "    X8_18 = dataset.Platform_GC.values\n",
    "    X8_19 = dataset.Platform_DS.values\n",
    "    X8_20 = dataset.Platform_XB.values\n",
    "    X8_25 = dataset.Platform_SAT.values\n",
    "\n",
    "\n",
    "    # Genre    \n",
    "    X9_1 = dataset.Genre_Platform.values\n",
    "    X9_2 = dataset.Genre_Shooter.values\n",
    "    X9_3 = dataset.Genre_Racing.values\n",
    "    X9_4 = dataset.Genre_Sports.values\n",
    "    X9_5 = dataset['Genre_Role-Playing'].values\n",
    "    X9_11 = dataset.Genre_Strategy.values\n",
    "    \n",
    "    # Rating\n",
    "    X10_4 = dataset.Rating_E.values\n",
    "    \n",
    "    # Publisher\n",
    "    X11_1 = dataset['Publisher_Nintendo'].values\n",
    "    X11_2 = dataset['Publisher_Microsoft Game Studios'].values\n",
    "    X11_6 = dataset['Publisher_Take-Two Interactive'].values\n",
    "    X11_8 = dataset['Publisher_Electronic Arts'].values\n",
    "    X11_9 = dataset['Publisher_Activision'].values\n",
    "    X11_10 = dataset['Publisher_Warner Bros. Interactive Entertainment'].values\n",
    "    X11_15 = dataset['Publisher_Disney Interactive Studios'].values\n",
    "    X11_18 = dataset['Publisher_Ubisoft'].values\n",
    "    X11_19 = dataset['Publisher_THQ'].values\n",
    "    X11_25 = dataset['Publisher_Konami Digital Entertainment'].values\n",
    "    \n",
    "    # Developer\n",
    "    #X12_20 = dataset['Developer_Ubisoft'].values\n",
    "    \n",
    "    X13 = dataset['Complete_Data'].values   \n",
    "    \n",
    "    X1 = dataset.JP_Sales.values\n",
    "    X2 = dataset.Critic_Count.values\n",
    "    X3 = dataset.Critic_Score.values\n",
    "    X4 = dataset.Year_of_Release.values\n",
    "    X5 = dataset.Other_Sales.values\n",
    "    X6 = dataset.User_Score.values\n",
    "    X7 = dataset.User_Count.values\n",
    "    \n",
    "    \n",
    "    # Par tattonnement on arrive a\n",
    "    X = np.array([X1,X1**2,X1*X5,X1*X4,X5*X4,X5**2,X4,X2,X3,X6,X7,X7**2,\n",
    "                  X8_4,\n",
    "                  X8_5,X8_7+X8_8+X8_10+X8_11,X8_17+X8_18+X8_19,X8_20,\n",
    "                  X8_25,\n",
    "                  X9_1,X9_2,X9_3+X9_4,X9_5,X9_11,\n",
    "                  X10_4,\n",
    "                  X11_1+X11_2,X11_6+X11_8+X11_9+X11_10+X11_15,X11_18+X11_19,X11_25,\n",
    "                  #X12_20,\n",
    "                  X13]).T\n",
    "    \n",
    "    \n",
    "    # On transforme pour moyenne = 0 et variance = 1\n",
    "    X_std = scaler(X)\n",
    "    \n",
    "    # On ajoute une colonne de 1\n",
    "    Ones = np.array([np.ones(len(dataset))]).T\n",
    "    X_std = np.concatenate((Ones,X_std),axis = 1)\n",
    "    \n",
    "    return X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createX_NA(dataset):\n",
    "    \n",
    "    # Variables Quantitatives\n",
    "    X1 = dataset.JP_Sales.values\n",
    "    X2 = dataset.Critic_Count.values\n",
    "    X3 = dataset.Critic_Score.values\n",
    "    X4 = dataset.Year_of_Release.values\n",
    "    X5 = dataset.Other_Sales.values\n",
    "    X6 = dataset.User_Score.values\n",
    "    X7 = dataset.User_Count.values\n",
    "    \n",
    "    # Platform\n",
    "    X8_4 = dataset.Platform_2600.values\n",
    "    X8_5 = dataset.Platform_X360.values\n",
    "    X8_6 = dataset.Platform_N64.values\n",
    "    X8_7 = dataset.Platform_Wii.values\n",
    "    X8_9 = dataset.Platform_XOne.values\n",
    "    X8_11 = dataset.Platform_SNES.values\n",
    "    X8_16 = dataset.Platform_GC.values\n",
    "    X8_18 = dataset.Platform_XB.values\n",
    "    X8_26 = dataset.Platform_SAT.values\n",
    "\n",
    "    # Genre    \n",
    "    X9_1 = dataset.Genre_Platform.values\n",
    "    X9_9 = dataset['Genre_Role-Playing'].values\n",
    "    \n",
    "    # Publisher\n",
    "    X11_1 = dataset['Publisher_Nintendo'].values\n",
    "    X11_2 = dataset['Publisher_Microsoft Game Studios'].values\n",
    "    X11_7 = dataset['Publisher_Activision'].values\n",
    "    X11_11 = dataset['Publisher_Warner Bros. Interactive Entertainment'].values\n",
    "    \n",
    "    \n",
    "    X12 = dataset['Complete_Data'].values  \n",
    "\n",
    "    X = np.array([X1**2,X1,X1*X5,X5,X1**2*X4**2,X4,X5**2,(X3**9)*X2,\n",
    "                  X8_4+X8_5+X8_6+X8_7+X8_9,X8_11,X8_16+X8_18,X8_26,\n",
    "                  X9_1,X9_9,\n",
    "                  X11_1+X11_2,X11_7+X11_11,\n",
    "                  X12]).T\n",
    "    \n",
    "    # On transforme pour moyenne = 0 et variance = 1\n",
    "    X_std = scaler(X)\n",
    "    \n",
    "    # On ajoute une colonne de 1\n",
    "    Ones = np.array([np.ones(len(dataset.JP_Sales))]).T\n",
    "    \n",
    "    X_std = np.concatenate((Ones,X_std),axis = 1)\n",
    "    \n",
    "    return X_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
