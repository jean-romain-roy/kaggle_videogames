{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Regression de Ridge (L2) par methode des moindres carres permettant la penalisation du surapprentissage.\n",
    "\n",
    "Arguments :\n",
    "\n",
    "    y : Variable d'interet (dimension : n x 1)\n",
    "    x : matrice contenant nos variables explicatives (dimension : n x p)\n",
    "    l : facteur qui permet de diminuer l'amplitude des coefficients de regression\n",
    "    minY : borne inférieur appliquer sur les predictions\n",
    "    maxY : borne supérieur appliquer sur les predictions\n",
    "    \n",
    "    ou,\n",
    "        n : nombre d'observation\n",
    "        p : nombre de variable explicative       \n",
    "        \n",
    "\n",
    "Retourne : \n",
    "\n",
    "    B = Matrices de nos coefficiants de regression (dimension (p+1) x 1)\n",
    "    Y_estime = Nouvelles predictions avec les coefficiants B\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def ridge_regression(y,x,l,minY,maxY):\n",
    "    \n",
    "    # Nombre d'observations\n",
    "    n = len(x)\n",
    "    \n",
    "    # Nombre de variable explicative\n",
    "    p = len(x.T)\n",
    "    \n",
    "    # Colonne de 1\n",
    "    Ones = np.array([np.ones(n)]).T\n",
    "    \n",
    "    # On l'emboite a notre matrice x\n",
    "    x_withOne = np.concatenate((Ones,x),axis = 1)    \n",
    "    \n",
    "    # Matrice identite de taille p+1\n",
    "    identi = np.identity(p+1) \n",
    "    identi[0][0] = 0 # on met un zero vis a vis le coeff b0 qui est l'ordonnee a l'origine\n",
    "    identi = np.dot(l,identi)\n",
    "    \n",
    "    # On multiplie X par soi meme\n",
    "    x2_withOne = np.dot(x_withOne.T,x_withOne)\n",
    "    \n",
    "    # On calcule la matrice de variance-covariance avec un biais de penalite\n",
    "    C = np.linalg.inv(x2_withOne + identi)\n",
    "    \n",
    "    # On calcule les coefficients de regression\n",
    "    B = np.dot(y,np.dot(x_withOne,C))\n",
    "    \n",
    "    # On calcule les predictions\n",
    "    Y_estime = np.dot(x_withOne,B)\n",
    "    \n",
    "    # On borne nos prediction\n",
    "    Y_estime_borne = Y_estime.clip(minY,maxY)\n",
    "    \n",
    "    return B, Y_estime_borne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Fonction permettant de transformer une matrice pour que ses colonnes aient une moyenne = 0 et une variance = 1\n",
    "\n",
    "Argument:\n",
    "    dataset : le jeu de donnees a transformer\n",
    "    \n",
    "Retourne :\n",
    "    dataset_std : le jeu de donnees transforme\n",
    "\n",
    "\"\"\"\n",
    "def scaler(dataset):\n",
    "    \n",
    "    # On calcule la moyenne pour chaque colonne\n",
    "    u = np.array([np.mean(dataset, axis=0)])\n",
    "    \n",
    "    # On soustrait les colonnes du jeu de donnees par ses moyennes\n",
    "    dataset_std = dataset - u\n",
    "    \n",
    "    # On calcule la variance pour chaque colonne\n",
    "    sigma = np.array([np.std(dataset_std, axis=0)])\n",
    "    \n",
    "    # On divise les colonnes du jeu de donnees par ses variances\n",
    "    dataset_std = dataset_std/sigma\n",
    "    \n",
    "    # Si contient des NaN cause par une division par 0 (si la variance etait de 0)\n",
    "    if(np.isnan(dataset_std).any()):\n",
    "        print(\"Colonne de variance = 0, contient des NaN\") # On affiche le message d'erreur\n",
    "        \n",
    "    \n",
    "    return dataset_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "L'algorithme R2_prev implemente une validation croise sur l'ensemble du jeu de donnees fournis\n",
    "\n",
    "Arguments:\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    X : Nos variables explicatives\n",
    "    \n",
    "\n",
    "\n",
    "Retourne:\n",
    "\n",
    "    R2_prev : Une mesure bornee entre [-inf, 1] qui represente le pouvoir predictif de nos estimations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def R2_prev(Y,W,X):\n",
    "    \n",
    "    # On multiplie X par soi meme\n",
    "    X2 = np.dot(X.T,X)  \n",
    "    \n",
    "    # The variance-covariance\n",
    "    C = np.linalg.inv(X2)\n",
    "    \n",
    "    # Hat Matrix (X*B = H*Y)\n",
    "    H = np.dot(np.dot(X,C),X.T)\n",
    "    \n",
    "    # We are only interested in the (i,i) values\n",
    "    H = np.diagonal(H)\n",
    "    \n",
    "    # Mean of Y\n",
    "    y_S = np.sum(Y)/float(len(Y))\n",
    "    \n",
    "    num = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        num += ((Y[i] - W[i])/float(1 - H[i]))**2\n",
    "\n",
    "    denom = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        denom += (Y[i] - y_S)**2\n",
    "    \n",
    "    R2_prev = (1 - num/denom)\n",
    "    \n",
    "    return R2_prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Selon le document MTH3302_CriteresProjet.pdf nous sommes evalues par notre root mean squared error (RMSE).\n",
    "On trouve ici son implementation.\n",
    "\n",
    "Arguments :\n",
    "    Y : La variable d'interet\n",
    "    W : Notre estimation de la variable d'interet\n",
    "    \n",
    "    \n",
    "Retourne:\n",
    "    rmse : L'erreur moyenne de nos predictions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def RMSE(Y,W):\n",
    "\n",
    "    n = len(Y)\n",
    "\n",
    "    total = 0.0\n",
    "    for i in range(n):\n",
    "        total += (Y[i] - W[i])**2\n",
    "        \n",
    "    rmse = total/float(n)\n",
    "        \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--- Variable Qualitative -> Table Binaire --- \n",
    "\n",
    "Afin de traiter nos variables qualitatives, nous avons une fonction qui la tranforme en table binaire \n",
    "avec un one bit encoder. \n",
    "\n",
    "    Disons que la variable explicative peut prendre 4 valeurs {Bleu, Vert, Jaune, Rouge},\n",
    "        \n",
    "          ID        X1\n",
    "        ----------------\n",
    "          1        Bleu\n",
    "          2        Bleu\n",
    "          3        Vert\n",
    "          4        Jaune\n",
    "          5        Vert\n",
    "          6        Rouge          \n",
    "         ...\n",
    "    \n",
    "    Suite a un encodage en 1 bit notre variable explicative X1 devient,\n",
    "    \n",
    "          ID        Bleu        Vert        Jaune        Rouge\n",
    "        -------------------------------------------------------\n",
    "          1          1           0            0            0\n",
    "          2          1           0            0            0\n",
    "          3          0           1            0            0\n",
    "          4          0           0            1            0\n",
    "          5          0           1            0            0\n",
    "          6          0           0            0            1\n",
    "                                ...\n",
    "                                \n",
    "\n",
    "Nous nous basons sur la fonction get_dummies() de la librairie Panda pour faire ceci.\n",
    "\n",
    "\n",
    "Arguments,\n",
    "\n",
    "    trainSet : le jeu de donnees de training\n",
    "    testSet : le jeu de donnees de test\n",
    "    varName : la variable qualitative que nous souhaitons transformer en tableau binaire\n",
    "    \n",
    "    \n",
    "Retourne, \n",
    "    trainSet_new : le jeu de donnees de training ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "    testSet_new : le jeu de donnees de test ou la variable qualitative a ete remplacee par un tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def qualiToBinary(trainSet, testSet, varName):\n",
    "    \n",
    "    # Genere la table binaire de la variable qualitative\n",
    "    trainVar_binary = pd.get_dummies(trainSet[varName],prefix=varName)\n",
    "    testVar_binary = pd.get_dummies(testSet[varName],prefix=varName)\n",
    "    \n",
    "    # On convertit nos tableaux binaires en Dataframe\n",
    "    trainVar_binary = pd.DataFrame(trainVar_binary)\n",
    "    testVar_binary = pd.DataFrame(testVar_binary)\n",
    "    \n",
    "    # On enleve la variable qualitative de nos jeux de donnees\n",
    "    trainSet_new = trainSet.drop([varName], axis=1)\n",
    "    testSet_new = testSet.drop([varName], axis=1)   \n",
    "\n",
    "    # On ajoute les nouvelles colonnes a nos jeux de donnees\n",
    "    trainSet_new = pd.concat([trainSet_new,trainVar_binary],axis=1)\n",
    "    testSet_new = pd.concat([testSet_new,testVar_binary],axis=1)\n",
    "    \n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees test\n",
    "    missing_categories = set(trainSet_new) - set(testSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        testSet_new[c] = 0\n",
    "\n",
    "    # On identifie les colonnes manquantes dans le jeu de donnees training\n",
    "    missing_categories = set(testSet_new) - set(trainSet_new)\n",
    "\n",
    "    # On ajoute ces colonnes manquantes avec une valeur par defaut de 0\n",
    "    for c in missing_categories:\n",
    "        trainSet_new[c] = 0\n",
    "\n",
    "\n",
    "    # On aligne nos jeux de donnees pour que les memes colonnes soient aux memes endroits\n",
    "    trainSet_new, testSet_new = trainSet_new.align(testSet_new, axis=1)\n",
    "    \n",
    "    # On retourne les jeux de donnees\n",
    "    return trainSet_new, testSet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement des données manquantes\n",
    "\n",
    "strat_imputation = [\"drop_na\", \"mean\", \"median\", \"most_frequent\", \"hot_deck\", \"cold_deck\"]\n",
    "\n",
    "def impute_data(data, nom_colonne, method = \"drop_na\"):\n",
    "    \"\"\"\n",
    "    On remplace les valeurs manquantes dans la colonne sélectionnée suivant l'une des stratégie ci-dessous:\n",
    "    - drop_na :  On supprime simplement les lignes avec des valeurs manquantes\n",
    "    - moyenne/médiane/mode : on remplace les valeurs manquantes par la moyenne, médiane ou mode de la colonne respectivement\n",
    "    - hot_deck : on cherche des données avec des caractéristiques similaires à la ligne avec la valeur manquante et\n",
    "                  on lui donne une valeur aléatoire de celles-ci\n",
    "    - cold_deck : on cherche des données avec des caractéristiques similaires à la ligne avec la valeur manquante et\n",
    "                  on lui donne une valeur particulière parmi celles-ci\n",
    "\n",
    "    \n",
    "    retourne la base de données imputée\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"drop_na\":\n",
    "        return data.dropna(subset = [nom_colonne])\n",
    "    \n",
    "    if method == \"mean\" or method == \"median\" or method == \"most_frequent\":\n",
    "        from sklearn.preprocessing import Imputer\n",
    "        imputer = Imputer(strategy = method)\n",
    "        imputed = data.copy()\n",
    "        imputed[nom_colonne] = imputer.fit_transform(data[[nom_colonne]])\n",
    "        return imputed\n",
    "    \n",
    "    if method == \"hot_deck\" :\n",
    "        #on itère sur la colonne, et si on trouve une valeur manquante, on cherche toutes les observations avec les\n",
    "        # ... mêmes valeurs de platform et genre ainsi qu'une valeur proche de other_sales. Puis on choisis une valeur\n",
    "        # ... aléatoire parmi celles-ci pour imputer notre valeur manquante.\n",
    "        imputed = data.copy()\n",
    "        for i in range(1,len(imputed.values)):\n",
    "            try:\n",
    "                if np.isnan(imputed.at[i, nom_colonne]):\n",
    "                    platform = imputed.at[i, 'Platform']\n",
    "                    genre = imputed.at[i, 'Genre']\n",
    "                    other_sales = imputed.at[i, 'Other_Sales']\n",
    "                    A = imputed.loc[(imputed[nom_colonne].notna()) & (imputed['Platform'] == platform) & (imputed['Genre'] == genre) & (imputed['Other_Sales'] < other_sales + 0.1) & (imputed['Other_Sales'] > other_sales - 0.1)]\n",
    "                    if len(A) == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        imputed.at[i, nom_colonne] = np.random.choice(A[nom_colonne])\n",
    "            except:\n",
    "                continue\n",
    "        imputed = imputed.dropna(subset = [nom_colonne])\n",
    "        return imputed\n",
    "    \n",
    "    if method == \"cold_deck\":\n",
    "        #même méthode que pour le hot_deck, sauf que cette fois_ci on ne choisis pas aléatoirement pour ne pas\n",
    "        #... ajouter de la variabilité au modèle. On choisit de manière déterministe, dans notre cas la première\n",
    "        imputed = data.copy()\n",
    "        for i in range(1,len(imputed.values)):\n",
    "            if np.isnan(imputed.at[i, nom_colonne]):\n",
    "                platform = imputed.at[i, 'Platform']\n",
    "                genre = imputed.at[i, 'Genre']\n",
    "                other_sales = imputed.at[i, 'Other_Sales']\n",
    "                A = imputed.loc[(imputed[nom_colonne].notna()) & (imputed['Platform'] == platform) & (imputed['Genre'] == genre) & (imputed['other_sales'] < other_sales + 0.05) & (imputed['other_sales'] > other_sales - 0.05)]\n",
    "                if len(A) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    imputed.at[i, nom_colonne] = A.values[0]\n",
    "        imputed = imputed.dropna(subset = [nom_colonne])\n",
    "        return imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies\n",
    "import numpy as np # calcul matriciel\n",
    "import pandas as pd # structure des donnees\n",
    "import matplotlib.pyplot as plt # graphiques\n",
    "\n",
    "# Chemin vers les jeux de donnees en format csv\n",
    "pathTest = \"./test3.csv\"\n",
    "pathTrain = \"./train3.csv\"\n",
    "\n",
    "# On importe les jeux de donnees\n",
    "df_test = pd.read_csv(pathTest, sep=',', index_col=0)\n",
    "df_train = pd.read_csv(pathTrain, sep=',', index_col=0)\n",
    "\n",
    "# On enleve la colonne Name qui ne sert pas a l'analyse\n",
    "df_train = df_train.drop(['Name'],axis=1)\n",
    "\n",
    "\n",
    "# --- Variables Explicatives ---\n",
    "\n",
    "#    Name : Nom du jeu\n",
    "#    Platform : Console sur laquelle le jeu fonctionne\n",
    "#    Year_of_Release : Année de sortie du jeu\n",
    "#    Genre\n",
    "#    Publisher\n",
    "#    JP_Sales : Nombre de ventes du jeu au Japon en millions d’unités\n",
    "#    Other_Sales : Nombre de ventes du jeu ailleurs dans le monde : Afrique, Asie sans le Japon, Europe sans l’Union Européenne et Amérique du Sud en millions d’unités\n",
    "#    Critic_Score : Score donné par Metacritic\n",
    "#    Critic_Count : Nombre de critiques prises en compte pour estimer le Critic_score\n",
    "#    User_Score : Score donné par les usagers de Metacritic\n",
    "#    User_Count : Nombre d’usagers considérés pour estimer le User_Score\n",
    "#    Developer : Compagnie créatrice du jeu\n",
    "#    Rating : Classement ESRB (Entertainment Software Rating Board) ie à qui s’addresse le jeu (tout public, majeur, adolescents, etc) \n",
    "\n",
    "\n",
    "# --- Variables d'Interet ---\n",
    "\n",
    "#    NA_sales : Nombre de ventes du jeu en Amérique du Nord en millions d’unités\n",
    "#    Global_Sales : Nombre de ventes total du jeu en millions d’unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_Release : 232\n",
      "Genre : 2\n",
      "Publisher : 49\n",
      "Critic_Score : 7186\n",
      "Critic_Count : 7186\n",
      "User_Score : 7653\n",
      "User_Count : 7653\n",
      "Developer : 5556\n",
      "Rating : 5677\n",
      "\n",
      "\n",
      "Year_of_Release : 35\n",
      "Publisher : 4\n",
      "Critic_Score : 1292\n",
      "Critic_Count : 1292\n",
      "User_Score : 1370\n",
      "User_Count : 1370\n",
      "Developer : 969\n",
      "Rating : 994\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on change les NaN grace a une technique d'imputation\n",
    "\n",
    "\"\"\"\n",
    "for i in df_train:\n",
    "    if(df_train[i].isna().sum() > 0):\n",
    "        print(\"%s : %d\" % (i,df_train[i].isna().sum()))\n",
    "        \n",
    "print('\\n')\n",
    "\n",
    "for i in df_test:\n",
    "    if(df_test[i].isna().sum() > 0):\n",
    "        print(\"%s : %d\" % (i,df_test[i].isna().sum()))\n",
    "\n",
    "df_train = impute_data(df_train, 'Year_of_Release', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Genre', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Publisher', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Critic_Score', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Critic_Count', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'User_Score', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'User_Count', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Developer', 'hot_deck').copy()\n",
    "df_train = impute_data(df_train, 'Rating', 'hot_deck').copy()\n",
    "\n",
    "df_test = impute_data(df_test, 'Year_of_Release', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Publisher', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Critic_Score', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Critic_Count', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'User_Score', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'User_Count', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Developer', 'hot_deck').copy()\n",
    "df_test = impute_data(df_test, 'Rating', 'hot_deck').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr. of categories Platform (train) : 17\n",
      "Nbr. of categories Platform (test) : 17 \n",
      "\n",
      "Nbr. of categories Genre (train) : 12\n",
      "Nbr. of categories Genre (test) : 12 \n",
      "\n",
      "Nbr. of categories Publisher (train) : 481\n",
      "Nbr. of categories Publisher (test) : 122 \n",
      "\n",
      "Nbr. of categories Developer (train) : 1564\n",
      "Nbr. of categories Developer (test) : 500 \n",
      "\n",
      "Nbr. of categories Rating (train) : 8\n",
      "Nbr. of categories Rating (test) : 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on transforme nos variables qualitatives en tableau binaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Variable Qualitative #1 : Platform\n",
    "print(\"Nbr. of categories Platform (train) : %d\" %(df_train.Platform.nunique()))\n",
    "print(\"Nbr. of categories Platform (test) : %d \\n\" %(df_test.Platform.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Platform') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #2 : Genre\n",
    "print(\"Nbr. of categories Genre (train) : %d\" %(df_train.Genre.nunique()))\n",
    "print(\"Nbr. of categories Genre (test) : %d \\n\" %(df_test.Genre.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Genre') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #3 : Publisher\n",
    "print(\"Nbr. of categories Publisher (train) : %d\" %(df_train.Publisher.nunique()))\n",
    "print(\"Nbr. of categories Publisher (test) : %d \\n\" %(df_test.Publisher.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test, 'Publisher') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #4 : Developer\n",
    "print(\"Nbr. of categories Developer (train) : %d\" %(df_train.Developer.nunique()))\n",
    "print(\"Nbr. of categories Developer (test) : %d \\n\" %(df_test.Developer.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Developer') # On binairise\n",
    "\n",
    "\n",
    "# Variable Qualitative #5 : Rating\n",
    "print(\"Nbr. of categories Rating (train) : %d\" %(df_train.Rating.nunique()))\n",
    "print(\"Nbr. of categories Rating (test) : %d \\n\" %(df_test.Rating.nunique()))\n",
    "df_train, df_test = qualiToBinary(df_train, df_test,'Rating') # On binairise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Ici on ajoute de nouvelles colonnes qui sont des combinaisons non-lineaires \n",
    "\n",
    "des autres colonnes ou de toute nouvelles informations.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On ajoute une colonne qui comptabilise le nombre de NaN pour chaque jeu video\n",
    "nbrOfNaN_train = ~(df_train.T.iloc[:].isna().sum().astype(bool))\n",
    "df_train['Contains_NaN'] = nbrOfNaN_train.astype(np.uint8)\n",
    "\n",
    "nbrOfNaN_test = ~(df_test.T.iloc[:].isna().sum().astype(bool))\n",
    "df_test['Contains_NaN'] = nbrOfNaN_test.astype(np.uint8)\n",
    "\n",
    "df_train['JP_Sales2'] = df_train.JP_Sales**2\n",
    "df_test['JP_Sales2'] = df_test.JP_Sales**2\n",
    "\n",
    "df_train['Other_Sales2'] = df_train.Other_Sales**2\n",
    "df_test['Other_Sales2'] = df_test.Other_Sales**2\n",
    "\n",
    "df_train['JP_Sales_Other_Sales'] = df_train.Other_Sales*df_train.JP_Sales\n",
    "df_test['JP_Sales_Other_Sales'] = df_test.Other_Sales*df_test.JP_Sales\n",
    "\n",
    "df_train['Other_Sales_Year_of_Release'] = df_train.Other_Sales*df_train.Year_of_Release\n",
    "df_test['Other_Sales_Year_of_Release'] = df_test.Other_Sales*df_test.Year_of_Release\n",
    "\n",
    "df_train['JP_Sales_Year_of_Release'] = df_train.JP_Sales*df_train.Year_of_Release\n",
    "df_test['JP_Sales_Year_of_Release'] = df_test.JP_Sales*df_test.Year_of_Release\n",
    "\n",
    "df_train['JP_Sales_Year2_of_Release2'] = df_train.JP_Sales**2*df_train.Year_of_Release**2\n",
    "df_test['JP_Sales_Year2_of_Release2'] = df_test.JP_Sales**2*df_test.Year_of_Release**2\n",
    "\n",
    "df_train['Critic_Score9_Critic_Count'] = df_train.Critic_Score**9*df_train.Critic_Count\n",
    "df_test['Critic_Score9_Critic_Count'] = df_test.Critic_Score**9*df_test.Critic_Count\n",
    "\n",
    "df_train['Critic_Score12_Critic_Count'] = df_train.Critic_Score**12*df_train.Critic_Count\n",
    "df_test['Critic_Score12_Critic_Count'] = df_test.Critic_Score**12*df_test.Critic_Count\n",
    "\n",
    "df_train['Critic_Score_Critic_Count'] = df_train.Critic_Score*df_train.Critic_Count\n",
    "df_test['Critic_Score_Critic_Count'] = df_test.Critic_Score*df_test.Critic_Count\n",
    "\n",
    "df_train['User_Score_User_Count'] = df_train.User_Score*df_train.User_Count\n",
    "df_test['User_Score_User_Count'] = df_test.User_Score*df_test.User_Count\n",
    "\n",
    "df_train['User_Score2'] = df_train.User_Score**2\n",
    "df_test['User_Score2'] = df_test.User_Score**2\n",
    "\n",
    "df_train['User_Count2'] = df_train.User_Count**2\n",
    "df_test['User_Count2'] = df_test.User_Count**2\n",
    "\n",
    "df_train['Critic_Count2'] = df_train.Critic_Count**2\n",
    "df_test['Critic_Count2'] = df_test.Critic_Count**2\n",
    "\n",
    "df_train['Critic_Score2'] = df_train.Critic_Score**2\n",
    "df_test['Critic_Score2'] = df_test.Critic_Score**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait une matrice de nos variables\n",
    "X_train = df_train.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "X_test = df_test.drop(['NA_Sales','Global_Sales'],axis=1)\n",
    "\n",
    "# On isole nos variables d'interet\n",
    "Y1 = df_train.Global_Sales.values\n",
    "Y2 = df_train.NA_Sales.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean-romain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne de variance = 0, contient des NaN\n",
      "Colonne de variance = 0, contient des NaN\n"
     ]
    }
   ],
   "source": [
    "# On transforme nos variables pour moyenne = 0 et var = 1\n",
    "X_train_std = scaler(X_train.values)\n",
    "X_test_std = scaler(X_test.values)\n",
    "\n",
    "# On enleve les colonnes ou nous avons des NaN (train)\n",
    "columnNaN = ~np.all(np.isnan(X_train_std), axis=0)\n",
    "X_train_std = X_train_std[:,columnNaN]\n",
    "X_test_std = X_test_std[:,columnNaN]\n",
    "\n",
    "# On enleve les colonnes ou nous avons des NaN (test)\n",
    "columnNaN = ~np.all(np.isnan(X_test_std), axis=0)\n",
    "X_train_std = X_train_std[:,columnNaN]\n",
    "X_test_std = X_test_std[:,columnNaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, minY = 0.058\n",
      "Global Sales, RMSE = 0.226 \n",
      "\n",
      "NA Sales, minY = 0.021\n",
      "NA Sales, RMSE = 0.121\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametre 1 (Global_Sales) - plancher des predictions\n",
    "best_RMSE = 1\n",
    "best_minY1 = 0\n",
    "\n",
    "maxY = np.max(Y1)\n",
    "l = 0.5\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minY = 0.05 + 0.001*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y1,X_train_std,l,minY,maxY)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y1,Y_est)\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_minY1 = minY\n",
    "\n",
    "        \n",
    "print(\"Global Sales, minY = %.3f\" % best_minY1)\n",
    "print(\"Global Sales, RMSE = %.3f \\n\" % best_RMSE)\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparametre 1 (NA_Sales) - plancher des predictions\n",
    "best_RMSE = 1\n",
    "best_minY2 = 0\n",
    "\n",
    "maxY = np.max(Y2)\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minY = 0.01 + 0.001*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y2,X_train_std,l,minY,maxY)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y2,Y_est)\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_minY2 = minY\n",
    "\n",
    "        \n",
    "print(\"NA Sales, minY = %.3f\" % best_minY2)\n",
    "print(\"NA Sales, RMSE = %.3f\" % best_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, maxY = 82.5407\n",
      "NA Sales, maxY = 41.3598\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametre 2 (Global_Sales) - plafond des predictions\n",
    "best_maxY1 = np.max(Y1)\n",
    "print(\"Global Sales, maxY = %.4f\" % best_maxY1)\n",
    "\n",
    "# Hyperparametre 2 (NA_Sales) - plafond des predictions\n",
    "best_maxY2 = np.max(Y2)\n",
    "print(\"NA Sales, maxY = %.4f\" % best_maxY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sales, minl = 0.0000\n",
      "Global Sales, RMSE = 0.2245 \n",
      "\n",
      "NA Sales, minl = 0.0000\n",
      "NA Sales, RMSE = 0.1205 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparametre 3 (Global_Sales) - parametre de penalisation\n",
    "nbr_ite = 30\n",
    "\n",
    "best_RMSE = 1\n",
    "best_l1 = 0\n",
    "rmse1 = np.zeros(nbr_ite)\n",
    "\n",
    "maxY = np.max(Y1)\n",
    "\n",
    "for i in range(nbr_ite):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minl = 0.05*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y1,X_train_std,minl,best_minY1,best_maxY1)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y1,Y_est)\n",
    "    rmse1[i] = rmse\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_l1 = minl\n",
    "\n",
    "        \n",
    "print(\"Global Sales, minl = %.4f\" % best_l1)\n",
    "print(\"Global Sales, RMSE = %.4f \\n\" % best_RMSE)\n",
    "\n",
    "\n",
    "# Hyperparametre 1 (NA_Sales) - parametre de penalisation\n",
    "best_RMSE = 1\n",
    "best_l2 = 0\n",
    "rmse2 = np.zeros(nbr_ite)\n",
    "\n",
    "maxY = np.max(Y2)\n",
    "\n",
    "for i in range(nbr_ite):\n",
    "    \n",
    "    # On met a jour l'hyperparametre\n",
    "    minl = 0.05*i\n",
    "    \n",
    "    # On calcule la regression\n",
    "    B, Y_est = ridge_regression(Y2,X_train_std,minl,best_minY2,best_maxY2)\n",
    "    \n",
    "    # On calcule notre erreur\n",
    "    rmse = RMSE(Y2,Y_est)\n",
    "    rmse2[i] = rmse\n",
    "    \n",
    "    if(rmse < best_RMSE):\n",
    "        best_RMSE = rmse\n",
    "        best_l2 = minl\n",
    "\n",
    "        \n",
    "print(\"NA Sales, minl = %.4f\" % best_l2)\n",
    "print(\"NA Sales, RMSE = %.4f \\n\" % best_RMSE)\n",
    "\n",
    "index = np.array(list(range(nbr_ite)))\n",
    "index = index*0.05\n",
    "\n",
    "plt.plot(index, rmse1, 'or')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Global Sales')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(index, rmse2, 'or')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('NA Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev :  -69.21658185505389\n",
      "RMSE :  0.22586018216771345\n"
     ]
    }
   ],
   "source": [
    "# Global Sales\n",
    "B1, Y_est1 = ridge_regression(Y1,X_train_std,0.6,best_minY1,best_maxY1)\n",
    "\n",
    "# Clip\n",
    "global_data = np.dot(X_train_std,np.delete(B1,0)) + B1[0]\n",
    "global_data = global_data.clip(best_minY1,best_maxY1)\n",
    "\n",
    "print(\"R2_prev : \",R2_prev(Y1,global_data,X_train_std))\n",
    "print(\"RMSE : \",RMSE(Y1,global_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_prev :  -41.540873815184774\n",
      "RMSE :  0.12108393469954265\n"
     ]
    }
   ],
   "source": [
    "# NA Sales\n",
    "B2, Y_est2 = ridge_regression(Y2,X_train_std,0.4,best_minY2,best_maxY2)\n",
    "\n",
    "# Clip\n",
    "na_data = np.dot(X_train_std,np.delete(B2,0)) + B2[0]\n",
    "na_data = na_data.clip(best_minY2,best_maxY2)\n",
    "\n",
    "print(\"R2_prev : \",R2_prev(Y2,na_data,X_train_std))\n",
    "print(\"RMSE : \",RMSE(Y2,na_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Processing du jeu de donnees test\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# On genere nos predictions\n",
    "global_data_test = np.dot(X_test_std,np.delete(B1,0)) + B1[0]\n",
    "na_data_test = np.dot(X_test_std,np.delete(B2,0)) + B2[0]\n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "global_data_test = global_data_test.clip(best_minY1,best_maxY1)  \n",
    "\n",
    "# On enleve les valeurs negatives\n",
    "na_data_test = na_data_test.clip(best_minY2,best_maxY2)\n",
    "\n",
    "# On vient prendre le dataframe comme canva\n",
    "df_test_estimated = pd.DataFrame([df_test.NA_Sales,df_test.Global_Sales]).copy().T\n",
    "\n",
    "# On assigne nos predictions aux colonnes\n",
    "df_test_estimated['Global_Sales'] = global_data_test\n",
    "df_test_estimated['NA_Sales'] = na_data_test\n",
    "\n",
    "# On sauvegarde nos predictions\n",
    "df_test_estimated.to_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
